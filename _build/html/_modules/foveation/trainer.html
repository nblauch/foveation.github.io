

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>foveation.trainer &mdash; foveation 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            foveation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../read_me.html">A biologically-inspired foveated interface for deep vision models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.sensing.html">foveation.sensing package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.arch.html">foveation.arch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.saccadenet.html">foveation.saccadenet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.trainer.html">foveation.trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Utilities &amp; Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.utils.html">foveation.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.demo.html">foveation.demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.paths.html">foveation.paths</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.probes.html">foveation.probes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/foveation.visualizer.html">foveation.visualizer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">foveation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
          <li class="breadcrumb-item"><a href="../foveation.html">foveation</a></li>
      <li class="breadcrumb-item active">foveation.trainer</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for foveation.trainer</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.amp</span><span class="w"> </span><span class="kn">import</span> <span class="n">autocast</span><span class="p">,</span> <span class="n">GradScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">emit_nvtx</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.lr_scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">ReduceLROnPlateau</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchmetrics</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">socket</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">OmegaConf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">uuid</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">hydra</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uuid</span><span class="w"> </span><span class="kn">import</span> <span class="n">uuid4</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">omegaconf</span><span class="w"> </span><span class="kn">import</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">OmegaConf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.fastaugs</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">fastT</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">ffcv</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">ffcv.transforms</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.pipeline.operation</span><span class="w"> </span><span class="kn">import</span> <span class="n">Operation</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.loader</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrderOption</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToTensor</span><span class="p">,</span> <span class="n">ToDevice</span><span class="p">,</span> <span class="n">Squeeze</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.fields.rgb_image</span><span class="w"> </span><span class="kn">import</span> <span class="n">CenterCropRGBImageDecoder</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.fields.basics</span><span class="w"> </span><span class="kn">import</span> <span class="n">IntDecoder</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">ffcv.fields</span><span class="w"> </span><span class="kn">import</span> <span class="n">IntField</span><span class="p">,</span> <span class="n">RGBImageField</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">.utils.fastaugs.loader</span><span class="w"> </span><span class="kn">import</span> <span class="n">FlashLoader</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c1"># non-ffcv capabilities only</span>
    <span class="k">pass</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.lr_scheduling</span><span class="w"> </span><span class="kn">import</span> <span class="n">LARS</span><span class="p">,</span> <span class="n">CosineDecayWithWarmup</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.probes</span><span class="w"> </span><span class="kn">import</span> <span class="n">SaccadeNetProbes</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.saccadenet</span><span class="w"> </span><span class="kn">import</span> <span class="n">SaccadeNet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_model</span><span class="p">,</span> <span class="n">reproducible_results</span><span class="p">,</span> <span class="n">get_random_name</span><span class="p">,</span> <span class="n">flatten_dict</span><span class="p">,</span> <span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">IMAGENET_STD</span><span class="p">,</span> <span class="n">add_to_all</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.losses</span><span class="w"> </span><span class="kn">import</span> <span class="n">SimCLRLoss</span><span class="p">,</span> <span class="n">VicRegLoss</span><span class="p">,</span> <span class="n">BarlowTwinsLoss</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.paths</span><span class="w"> </span><span class="kn">import</span> <span class="n">SAVE_DIR</span><span class="p">,</span> <span class="n">SLOW_DIR</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="Trainer">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer">[docs]</a>
<span class="nd">@add_to_all</span><span class="p">(</span><span class="n">__all__</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Trainer</span><span class="p">:</span>
<div class="viewcode-block" id="Trainer.__init__">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gpu</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">DictConfig</span><span class="p">,</span> <span class="n">load_checkpoint</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize trainer with hydra configuration</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            gpu: which gpu to run on</span>
<span class="sd">            cfg: Hydra configuration object</span>
<span class="sd">            load_checkpoint: Whether to load checkpoint</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        
        <span class="c1"># Convert config to dictionary once for efficiency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">resolve</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict_flat</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span><span class="p">)</span>
        
        <span class="n">reproducible_results</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># Extract distributed training parameters from config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gpu</span> <span class="o">=</span> <span class="n">gpu</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">gpu</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SLURM_NODEID&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">))</span> <span class="o">*</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">ngpus</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">world_size</span>
        <span class="c1"># Use computed dist_url if available (for distributed), otherwise use default</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_url</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="p">,</span> <span class="s1">&#39;dist_url&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;tcp://localhost:</span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="c1"># Set up distributed training if needed</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">setup_distributed</span><span class="p">()</span>
        
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">uid</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">uuid4</span><span class="p">())</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_remote_logger</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_amp</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">)</span>

        <span class="c1"># Create SSL model, scaler, and optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_and_scaler</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">train_probes_only</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">num_features</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">n_probe_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">mlp_spec</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NUM PROBE LAYERS:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_probe_layers</span><span class="p">)</span>

        <span class="c1"># Create linear probes (trained without label smoothing)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_layer_probes_only</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">last_layer_probes_only</span>
        <span class="n">mlp_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">mlp_spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probes</span> <span class="o">=</span> <span class="n">SaccadeNetProbes</span><span class="p">(</span><span class="n">mlp_spec</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">fix_agg</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> 
                                        <span class="n">dropout</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">dropout_probes</span><span class="p">,</span>
                                        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">probes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">],</span> <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loader_transforms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">loader_transforms</span>

        <span class="c1"># Create DataLoader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_dataset</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_labels</span> <span class="o">=</span> <span class="mi">1</span>
            
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_loader</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">subset</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_val_loader</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">subset</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_train_examples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_classes</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NUM TRAINING EXAMPLES:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train_examples</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_logger</span><span class="p">()</span>

        <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">label_smoothing</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Multilabel loss does not support label smoothing&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">label_smoothing</span><span class="p">)</span>
                
        <span class="c1"># Define SSL loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span> <span class="o">=</span> <span class="kc">False</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">train_probes_only</span> <span class="k">else</span> <span class="kc">True</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training backbone: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum_schedule</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">contr_pairs_per_im</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="p">,</span> <span class="s1">&#39;contr_pairs_per_image&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">contr_pairs_per_im</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;simclr&#39;</span><span class="p">,</span> <span class="s1">&#39;seqjepa&#39;</span><span class="p">],</span> <span class="s2">&quot;Only simclr and seqjepa loss is supported for more than 1 contrastive pair per image. check saccade policy or modify the code.&quot;</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;simclr&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ssl_loss</span> <span class="o">=</span> <span class="n">SimCLRLoss</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">simclr</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span> <span class="n">pairs_per_sample</span><span class="o">=</span><span class="n">contr_pairs_per_im</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;vicreg&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ssl_loss</span> <span class="o">=</span> <span class="n">VicRegLoss</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">vicreg</span><span class="o">.</span><span class="n">sim_coeff</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">vicreg</span><span class="o">.</span><span class="n">std_coeff</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">vicreg</span><span class="o">.</span><span class="n">cov_coeff</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;barlow&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ssl_loss</span> <span class="o">=</span> <span class="n">BarlowTwinsLoss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">bn</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">barlow</span><span class="o">.</span><span class="n">lambd</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;ipcl&quot;</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss not available, YET&quot;</span><span class="p">)</span>
            <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s2">&quot;supervised&quot;</span> <span class="ow">or</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="s1">&#39;supervised_multilabel&#39;</span><span class="p">:</span>
            <span class="c1"># raise ValueError(&#39;Supervised loss not supported for SaccadeNet&#39;)</span>
            <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">sup_policy</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;multi_random&#39;</span><span class="p">,</span> <span class="s1">&#39;multi_random_nearcenter&#39;</span><span class="p">,</span> <span class="s1">&#39;multi_random_tok&#39;</span><span class="p">,</span> <span class="s1">&#39;multi_random_nearcenter_tok&#39;</span><span class="p">,</span> <span class="s1">&#39;multi_random_train&#39;</span><span class="p">,</span> <span class="s1">&#39;deepgazeI&#39;</span><span class="p">,</span> <span class="s1">&#39;deepgazeIIE&#39;</span><span class="p">]:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">sup_policy</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span> <span class="o">=</span> <span class="kc">True</span>     
            <span class="bp">self</span><span class="o">.</span><span class="n">add_supervised_meters</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss not available&quot;</span><span class="p">)</span>
            <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">contr_pairs_per_im</span><span class="si">}</span><span class="s2"> contrastive pairs per image&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train_examples</span> <span class="o">//</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">create_optimizer</span><span class="p">()</span>

        <span class="c1"># Load models if checkpoint exists</span>
        <span class="k">if</span> <span class="n">load_checkpoint</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">()</span></div>


<div class="viewcode-block" id="Trainer.setup_distributed">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.setup_distributed">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">setup_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize distributed training process group.&quot;&quot;&quot;</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_url</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.cleanup_distributed">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.cleanup_distributed">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">cleanup_distributed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up distributed training process group.&quot;&quot;&quot;</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span></div>


<div class="viewcode-block" id="Trainer.create_optimizer">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.create_optimizer">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create and configure optimizers for model and probes.</span>
<span class="sd">        </span>
<span class="sd">        Sets up separate optimizers for the main model and linear probes,</span>
<span class="sd">        with appropriate weight decay settings and learning rate scaling.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;sgd&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;adamw&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s2">&quot;lars&quot;</span>

        <span class="c1"># Only do weight decay on non-batchnorm parameters</span>
        <span class="n">all_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">())</span>
        <span class="n">bn_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_params</span> <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;bn&#39;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)]</span>
        <span class="n">other_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_params</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="s1">&#39;bn&#39;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">bn_params</span><span class="p">):</span>
            <span class="n">param_groups</span> <span class="o">=</span> <span class="p">[{</span>
                <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">bn_params</span><span class="p">,</span>
                <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.</span>
            <span class="p">},</span> <span class="p">{</span>
                <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">other_params</span><span class="p">,</span>
                <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">weight_decay</span>
            <span class="p">}]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_groups</span> <span class="o">=</span> <span class="p">[{</span>
                <span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">other_params</span><span class="p">,</span>
                <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">weight_decay</span>
            <span class="p">}]</span>
        <span class="n">probe_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="n">scaled_lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">base_lr</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span> <span class="o">/</span> <span class="mf">256.0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;sgd&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">param_groups</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">probe_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">momentum</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s1">&#39;adamw&#39;</span><span class="p">:</span>
            <span class="c1"># We use a big eps value to avoid instabilities with fp16 training</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">param_groups</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">probe_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s2">&quot;lars&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">LARS</span><span class="p">(</span><span class="n">param_groups</span><span class="p">)</span>  <span class="c1"># to use with convnet and large batches</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span> <span class="o">=</span> <span class="n">LARS</span><span class="p">(</span><span class="n">probe_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">optimizer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">standard_probe_optim</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">standard_probe_optim</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">standard_probe_optim</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_schedule</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">==</span> <span class="s1">&#39;cosine_decay_with_warmup&#39;</span><span class="p">:</span>
                <span class="n">warmup_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train_examples</span> <span class="o">//</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">CosineDecayWithWarmup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">base_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">end_lr_ratio</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_by_step</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">==</span> <span class="s1">&#39;reduce_on_plateau&#39;</span><span class="p">:</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">val_every</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;for reduce on plateau, must validate every epoch&#39;</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">,</span> <span class="s1">&#39;for now, only implemented for checking validation accuracy&#39;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> 
                                                    <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> 
                                                    <span class="n">factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">lr_decay_factor</span><span class="p">,</span> 
                                                    <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">patience_epochs</span><span class="p">,</span> 
                                                    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> 
                                                    <span class="n">threshold_mode</span><span class="o">=</span><span class="s1">&#39;rel&#39;</span><span class="p">,</span>
                                                    <span class="n">cooldown</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                    <span class="n">min_lr</span><span class="o">=</span><span class="n">scaled_lr</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">end_lr_ratio</span><span class="p">,</span>
                                                    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span>
                                                    <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_by_step</span> <span class="o">=</span> <span class="kc">False</span> </div>


<div class="viewcode-block" id="Trainer.create_train_loader">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.create_train_loader">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_train_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batches_ahead</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create training data loader with appropriate transforms and augmentation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            train_dataset (str): Path to training dataset file</span>
<span class="sd">            subset (float, optional): Fraction of dataset to use for faster prototyping</span>
<span class="sd">            batches_ahead (int): Number of batches to prefetch</span>
<span class="sd">            phase (str): Training phase (&#39;train&#39; or other)</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            FlashLoader: Configured data loader for training</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">labels_device</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">labels_device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
        <span class="n">img_device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">load_cpu</span> <span class="k">else</span> <span class="n">labels_device</span>
        <span class="n">train_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">train_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;just resizing, no crops&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ffcv</span><span class="o">.</span><span class="n">fields</span><span class="o">.</span><span class="n">rgb_image</span><span class="o">.</span><span class="n">RandomResizedCropRGBImageDecoder</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">resolution</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">resolution</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">ratio</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output_size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">output_size</span><span class="si">}</span><span class="s2">, scale: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">scale</span><span class="si">}</span><span class="s2">, ratio: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">ratio</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">image_pipeline</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">]</span>

        <span class="n">other_key</span> <span class="o">=</span> <span class="s1">&#39;label&#39;</span>
        <span class="n">other_field</span> <span class="o">=</span> <span class="n">IntField</span>
        <span class="n">other_pipeline</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Operation</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">IntDecoder</span><span class="p">(),</span>
            <span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">Squeeze</span><span class="p">(),</span>
            <span class="n">ToDevice</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">labels_device</span><span class="p">),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">pipelines</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image_pipeline</span><span class="p">,</span>
            <span class="n">other_key</span><span class="p">:</span> <span class="n">other_pipeline</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="n">after_batch_pipelines</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">loader_transforms</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">after_batch_pipelines</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">fastT</span><span class="o">.</span><span class="n">Compose</span><span class="p">((</span>
                <span class="n">fastT</span><span class="o">.</span><span class="n">ToTorchImage</span><span class="p">(</span><span class="n">img_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">from_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">fastT</span><span class="o">.</span><span class="n">NormalizeGPU</span><span class="p">(</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">IMAGENET_STD</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="p">))}</span>

        <span class="n">custom_fields</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">RGBImageField</span><span class="p">,</span>
            <span class="n">other_key</span><span class="p">:</span> <span class="n">other_field</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">custom_field_mapper</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">order</span> <span class="o">=</span> <span class="n">OrderOption</span><span class="o">.</span><span class="n">RANDOM</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span> <span class="k">else</span> <span class="n">OrderOption</span><span class="o">.</span><span class="n">QUASI_RANDOM</span>

        <span class="c1"># Create data loader</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">FlashLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
                        <span class="n">os_cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">in_memory</span><span class="p">,</span>
                        <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">pipelines</span><span class="o">=</span><span class="n">pipelines</span><span class="p">,</span>
                        <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
                        <span class="n">custom_fields</span><span class="o">=</span><span class="n">custom_fields</span><span class="p">,</span>
                        <span class="n">custom_field_mapper</span><span class="o">=</span><span class="n">custom_field_mapper</span><span class="p">,</span>
                        <span class="n">after_batch_pipelines</span><span class="o">=</span><span class="n">after_batch_pipelines</span><span class="p">,</span>
                        <span class="n">batches_ahead</span><span class="o">=</span><span class="n">batches_ahead</span><span class="p">,</span>
                        <span class="p">)</span>
        
        <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">subset</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;using subset of </span><span class="si">{</span><span class="n">subset</span><span class="si">}</span><span class="s1"> in train loader&#39;</span><span class="p">)</span>
            <span class="n">order</span> <span class="o">=</span> <span class="n">OrderOption</span><span class="o">.</span><span class="n">RANDOM</span> <span class="c1"># quasi-random doesn&#39;t appear supported with a subset</span>
            <span class="n">len_dset</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">loader</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">subset</span> <span class="o">*</span> <span class="n">len_dset</span><span class="p">))</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">FlashLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
                <span class="n">os_cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">in_memory</span><span class="p">,</span>
                <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">pipelines</span><span class="o">=</span><span class="n">pipelines</span><span class="p">,</span>
                <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                <span class="n">custom_fields</span><span class="o">=</span><span class="n">custom_fields</span><span class="p">,</span>
                <span class="n">custom_field_mapper</span><span class="o">=</span><span class="n">custom_field_mapper</span><span class="p">,</span>
                <span class="n">after_batch_pipelines</span><span class="o">=</span><span class="n">after_batch_pipelines</span><span class="p">,</span>
                <span class="n">batches_ahead</span><span class="o">=</span><span class="n">batches_ahead</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;train loader: </span><span class="si">{</span><span class="n">loader</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loader</span> </div>


<div class="viewcode-block" id="Trainer.create_val_loader">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.create_val_loader">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_val_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val_dataset</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create validation data loader with center crop transforms.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            val_dataset (str): Path to validation dataset file</span>
<span class="sd">            subset (float, optional): Fraction of dataset to use</span>
<span class="sd">            ratio (float, optional): crop linear ratio</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            FlashLoader: Configured data loader for validation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels_device</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">img_device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">load_cpu</span> <span class="k">else</span> <span class="n">labels_device</span>

        <span class="n">val_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">val_path</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span>
        <span class="n">res_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">resolution</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">resolution</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;val loader crop ratio: </span><span class="si">{</span><span class="n">ratio</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>    
        <span class="n">decoder</span> <span class="o">=</span> <span class="n">CenterCropRGBImageDecoder</span><span class="p">(</span><span class="n">res_tuple</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">)</span>
        <span class="n">image_pipeline</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder</span><span class="p">]</span>
        <span class="n">after_batch_pipelines</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">fastT</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">fastT</span><span class="o">.</span><span class="n">ToTorchImage</span><span class="p">(</span><span class="n">img_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">from_numpy</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">fastT</span><span class="o">.</span><span class="n">NormalizeGPU</span><span class="p">(</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">IMAGENET_STD</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="p">])}</span>

        <span class="n">other_key</span> <span class="o">=</span> <span class="s1">&#39;label&#39;</span>
        <span class="n">other_field</span> <span class="o">=</span> <span class="n">IntField</span>
        <span class="n">other_pipeline</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Operation</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">IntDecoder</span><span class="p">(),</span>
            <span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">Squeeze</span><span class="p">(),</span>
            <span class="n">ToDevice</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">labels_device</span><span class="p">),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="n">pipelines</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image_pipeline</span><span class="p">,</span>
            <span class="n">other_key</span><span class="p">:</span> <span class="n">other_pipeline</span><span class="p">,</span>
        <span class="p">}</span>


        <span class="n">order</span> <span class="o">=</span> <span class="n">OrderOption</span><span class="o">.</span><span class="n">SEQUENTIAL</span>

        <span class="n">loader</span> <span class="o">=</span> <span class="n">FlashLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                        <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
                        <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">pipelines</span><span class="o">=</span><span class="n">pipelines</span><span class="p">,</span>
                        <span class="n">custom_fields</span><span class="o">=</span><span class="p">{</span>
                            <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">RGBImageField</span><span class="p">,</span>
                            <span class="n">other_key</span><span class="p">:</span> <span class="n">other_field</span><span class="p">,</span>
                        <span class="p">},</span>
                        <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
                        <span class="n">after_batch_pipelines</span><span class="o">=</span><span class="n">after_batch_pipelines</span><span class="p">,</span>
                        <span class="p">)</span>
        
        <span class="k">if</span> <span class="n">subset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;using subset of </span><span class="si">{</span><span class="n">subset</span><span class="si">}</span><span class="s1"> in val loader&#39;</span><span class="p">)</span>
            <span class="n">len_dset</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">len_dset</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">subset</span> <span class="o">*</span> <span class="n">len_dset</span><span class="p">))</span>
            <span class="n">loader</span> <span class="o">=</span> <span class="n">FlashLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
                            <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span>
                            <span class="n">os_cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">in_memory</span><span class="p">,</span>
                            <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">indices</span><span class="o">=</span><span class="n">indices</span><span class="p">,</span>
                            <span class="n">pipelines</span><span class="o">=</span><span class="n">pipelines</span><span class="p">,</span>
                            <span class="n">custom_fields</span><span class="o">=</span><span class="p">{</span>
                                <span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">RGBImageField</span><span class="p">,</span>
                                <span class="n">other_key</span><span class="p">:</span> <span class="n">other_field</span><span class="p">,</span>
                            <span class="p">},</span>
                            <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
                            <span class="n">after_batch_pipelines</span><span class="o">=</span><span class="n">after_batch_pipelines</span><span class="p">,</span>
                            <span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;val loader: </span><span class="si">{</span><span class="n">loader</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loader</span></div>


<div class="viewcode-block" id="Trainer.create_standard_loader">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.create_standard_loader">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_standard_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span><span class="p">,</span> <span class="n">resolution</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create standard data loader with basic transforms.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            dataset: Dataset to create loader for</span>
<span class="sd">            batch_size (int): Batch size for the data loader</span>
<span class="sd">            num_workers (int): Number of worker processes for data loading</span>
<span class="sd">            resolution (int): Target resolution to resize images to</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            DataLoader: Standard PyTorch data loader with basic image transforms</span>
<span class="sd">                       (ToTensor, Resize, Normalize) applied</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="n">resolution</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">IMAGENET_MEAN</span><span class="p">,</span> <span class="n">IMAGENET_STD</span><span class="p">),</span>
            <span class="p">])</span> 
        <span class="n">dataset</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="n">loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loader</span></div>

            

<div class="viewcode-block" id="Trainer.create_model_and_scaler">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.create_model_and_scaler">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_model_and_scaler</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create and configure the neural network model and gradient scaler.</span>
<span class="sd">        Returns:</span>
<span class="sd">            tuple: (model, scaler) where model is the configured neural network</span>
<span class="sd">                   and scaler is the gradient scaler for mixed precision training</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">growth_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">SaccadeNet</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span> <span class="k">else</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">loss</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;SaccadeNet loss (</span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="si">}</span><span class="s2">) must match training.loss (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">loss</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">channels_last</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="o">.</span><span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
                                                       <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">load_cpu</span> <span class="k">else</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">],</span>
                                                       <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                       <span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">scaler</span></div>


<div class="viewcode-block" id="Trainer.reset_model">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.reset_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset the model by recreating it from scratch.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_model_and_scaler</span><span class="p">()</span></div>


<div class="viewcode-block" id="Trainer.train">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.train">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute the main training loop.</span>
<span class="sd">        </span>
<span class="sd">        Runs training for the specified number of epochs, performing validation</span>
<span class="sd">        at regular intervals and saving checkpoints. Handles learning rate scheduling</span>
<span class="sd">        and early stopping.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: Training statistics for all epochs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We scale the number of max steps w.t the number of examples in the training set</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_train_examples</span> <span class="o">//</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
        <span class="n">all_stats</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">extra_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">train_loss</span><span class="p">,</span> <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loop</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">log_level</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">extra_dict</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                    <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span>
                <span class="p">}</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_dict</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">),</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">val_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">val_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_and_log</span><span class="p">(</span><span class="n">extra_dict</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">extra_dict</span><span class="p">,</span> <span class="n">phase</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">))</span>
                <span class="n">stats</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_stats</span><span class="p">)</span>

                <span class="c1"># update lr and check for early stopping</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_by_step</span><span class="p">:</span>
                    <span class="n">metric</span> <span class="o">=</span> <span class="n">val_stats</span><span class="p">[</span><span class="s1">&#39;top_1_val_p0&#39;</span><span class="p">]</span>
                    <span class="n">prev_lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span> <span class="c1"># auto-changes self.optimizer</span>
                    <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_probe_optim</span><span class="p">:</span>
                        <span class="c1"># also update probe lr</span>
                        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                            <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
                    
                    <span class="k">if</span> <span class="n">prev_lr</span> <span class="o">==</span> <span class="n">lr</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="c1"># trigger early stopping</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">stop_early_epoch</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">all_stats</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">all_stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">all_stats</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

            <span class="c1"># Run checkpointing</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="c1"># debugging</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">stop_early_epoch</span><span class="o">&gt;</span><span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">&gt;=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">stop_early_epoch</span><span class="p">:</span> <span class="k">break</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">state_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">probes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span><span class="p">,</span>
                <span class="n">lr_scheduler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="s1">&#39;final_weights.pth&#39;</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">all_stats</span></div>

            
<div class="viewcode-block" id="Trainer.eval_and_log">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.eval_and_log">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">eval_and_log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extra_dict</span><span class="o">=</span><span class="p">{}):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run validation and log results.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            extra_dict (dict): Additional data to include in logging</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: Validation statistics</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loop</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">stats</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_dict</span><span class="p">),</span> <span class="s1">&#39;val&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">stats</span> </div>


<div class="viewcode-block" id="Trainer.load_checkpoint">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.load_checkpoint">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ckpt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load model and optimizer state from checkpoint.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            ckpt (dict, optional): Checkpoint dictionary. If None, loads from</span>
<span class="sd">                                  default checkpoint file in log folder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if not provided, try to load checkpoint. if nonexistent, return</span>
        <span class="k">if</span> <span class="n">ckpt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="s2">&quot;model.pth&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;resuming from checkpoint&quot;</span><span class="p">)</span>
                <span class="n">ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="s2">&quot;model.pth&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="s1">&#39;optimizer&#39;</span> <span class="ow">in</span> <span class="n">ckpt</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;optimizer&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">train_probes_only</span><span class="p">:</span> <span class="c1"># train_probes_only means train_probes_only_from_scratch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;probes&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="s1">&#39;optimizer_probes&#39;</span> <span class="ow">in</span> <span class="n">ckpt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s2">&quot;optimizer_probes&quot;</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span> <span class="s1">&#39;load_state_dict&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="s1">&#39;lr_scheduler&#39;</span> <span class="ow">in</span> <span class="n">ckpt</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s1">&#39;lr_scheduler&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># training probes only from checkpoint</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span></div>


<div class="viewcode-block" id="Trainer.checkpoint">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.checkpoint">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save checkpoint at regular intervals based on checkpoint frequency.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">checkpoint_freq</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="Trainer.save_checkpoint">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.save_checkpoint">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save model and optimizer state to checkpoint file.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            epoch (int): Current training epoch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">train_probes_only</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> 
                <span class="n">probes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
                <span class="n">optimizer_probes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">lr_scheduler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="n">params</span>
            <span class="p">)</span>
            <span class="n">save_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;probes.pth&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> 
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
                <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">probes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> 
                <span class="n">optimizer_probes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">lr_scheduler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="n">params</span>
            <span class="p">)</span>
            <span class="n">save_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;model.pth&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="n">save_name</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.train_loop">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.train_loop">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">max_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute one epoch of training.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            epoch (int): Current epoch number</span>
<span class="sd">            max_batches (int, optional): Maximum number of batches to process</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            tuple: (average_loss, training_stats)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pretrained_model&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;freeze_backbone&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">backbone</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">iterator</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">ix</span><span class="p">,</span> <span class="n">loaders</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">epoch</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">max_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">ix</span> <span class="o">&gt;=</span> <span class="n">max_batches</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="c1"># Get lr</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_schedule</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler_by_step</span><span class="p">:</span>
                <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">(</span><span class="n">ix</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                    <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
                
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">standard_probe_optim</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
                        <span class="n">g</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>

            <span class="c1"># Get data</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">loaders</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">loaders</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loaders</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">:</span>
                <span class="n">images_1</span> <span class="o">=</span> <span class="n">loaders</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">images</span><span class="p">,</span> <span class="n">images_1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">labels</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">ssl_batch</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># supervised or saccadenet</span>
                <span class="n">ssl_batch</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
            
            <span class="c1"># SSL Training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="p">:</span>
                <span class="n">total_loss_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)):</span>
                    <span class="n">saccade_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">setting</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                    <span class="n">embeddings</span><span class="p">,</span> <span class="n">list_representation</span><span class="p">,</span> <span class="n">x_fixs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="o">**</span><span class="n">saccade_kwargs</span><span class="p">)</span>      
                    
                    <span class="c1"># Compute Loss</span>
                    <span class="n">step_num</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">contr_pairs_per_im</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="p">,</span> <span class="s1">&#39;contr_pairs_per_image&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">:</span> <span class="c1"># category supervision</span>
                        <span class="n">current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_trn&#39;</span><span class="p">](</span><span class="n">current_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                        <span class="n">meters</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;multilabel_acc_trn&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;top_1_trn&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_trn&#39;</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">meters</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">embeddings</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">labels</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                        <span class="n">total_loss_train</span> <span class="o">=</span> <span class="n">total_loss_train</span> <span class="o">+</span> <span class="n">current_loss</span>
                        <span class="n">step_num</span> <span class="o">=</span> <span class="n">step_num</span><span class="o">+</span><span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span> <span class="c1"># simclr, barlow, vicreg</span>
                        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                        <span class="k">if</span> <span class="s2">&quot;simclr&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span><span class="p">:</span>
                            <span class="n">loss_num</span><span class="p">,</span> <span class="n">loss_denum</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ssl_loss</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">embeddings</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
                            <span class="n">total_loss_train</span> <span class="o">=</span> <span class="n">total_loss_train</span> <span class="o">+</span> <span class="n">loss_num</span> <span class="o">+</span> <span class="n">loss_denum</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">total_loss_train</span> <span class="o">=</span> <span class="n">total_loss_train</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ssl_loss</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">embeddings</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
                        <span class="n">step_num</span> <span class="o">=</span> <span class="n">step_num</span><span class="o">+</span><span class="mi">1</span>
                    
                    <span class="n">total_loss_train</span> <span class="o">=</span> <span class="n">total_loss_train</span> <span class="o">/</span> <span class="p">(</span><span class="n">step_num</span><span class="o">*</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">grad_accum_steps</span><span class="p">)</span>
                    <span class="c1"># scaler enabling is controlled at creation, not during use</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">total_loss_train</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">ix</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">grad_accum_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="c1"># take a step along the accumulated gradients</span>
                        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">clip_grad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
                            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">clip_grad</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                        <span class="n">check_scaler_scale</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># ======================================================================                    </span>
            <span class="c1">#  Online linear probes training</span>
            <span class="c1"># ======================================================================</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">no_probes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">ssl_batch</span><span class="p">:</span>
                    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

                <span class="n">inputs</span> <span class="o">=</span> <span class="n">images</span>

                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)):</span>
                        <span class="n">embeddings</span><span class="p">,</span> <span class="n">list_representation</span><span class="p">,</span> <span class="n">x_fixs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">setting</span><span class="o">=</span><span class="s1">&#39;supervised&#39;</span><span class="p">)</span>

                <span class="c1"># Train probes</span>
                <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)):</span>
                    <span class="n">list_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="p">(</span><span class="n">list_representation</span><span class="p">)</span>
                    <span class="n">loss_classif</span> <span class="o">=</span> <span class="mf">0.</span>
                    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">)):</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_layer_probes_only</span> <span class="ow">and</span> <span class="n">l</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                            <span class="k">continue</span>
                        <span class="c1"># Compute classif loss</span>
                        <span class="n">current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">labels</span><span class="p">)</span>
                        <span class="n">loss_classif</span> <span class="o">=</span> <span class="n">loss_classif</span> <span class="o">+</span> <span class="n">current_loss</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)](</span><span class="n">current_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                        <span class="n">meters</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;multilabel_acc_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;top_1_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="s1">&#39;top_5_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span>
                        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">meters</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">list_outputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">labels</span><span class="p">)</span>
        
                <span class="n">loss_classif</span> <span class="o">=</span> <span class="n">loss_classif</span> <span class="o">/</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">grad_accum_steps</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss_classif</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">ix</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">grad_accum_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># take a step along the accumulated gradients</span>
                    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">clip_grad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="p">)</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">clip_grad</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                    <span class="n">check_scaler_scale</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Logging</span>
            <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">log_level</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="p">:</span> 
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">](</span><span class="n">total_loss_train</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_loss_train</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                    <span class="n">group_lrs</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">):</span>
                        <span class="n">group_lrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">group_lrs</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_probes</span><span class="o">.</span><span class="n">param_groups</span><span class="p">):</span>
                        <span class="n">group_lrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">group</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span><span class="si">:</span><span class="s1">.5f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ep&#39;</span><span class="p">,</span> <span class="s1">&#39;iter&#39;</span><span class="p">,</span> <span class="s1">&#39;shape&#39;</span><span class="p">,</span> <span class="s1">&#39;lrs&#39;</span><span class="p">]</span>
                <span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">epoch</span><span class="p">,</span> <span class="n">ix</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">group_lrs</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">log_level</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="p">:</span> 
                        <span class="n">names</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
                        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">total_loss_train</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">no_probes</span><span class="p">:</span>
                        <span class="n">names</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;loss_c&#39;</span><span class="p">]</span>
                        <span class="n">values</span> <span class="o">+=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">loss_classif</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="p">:</span>
                            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_classif</span><span class="p">)</span>

                <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">=</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">values</span><span class="p">))</span>
                <span class="n">iterator</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>

        <span class="c1"># Return epoch&#39;s log</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">log_level</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">](</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">iterator</span><span class="o">.</span><span class="n">format_dict</span><span class="p">[</span><span class="s2">&quot;elapsed&quot;</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">allow_nans</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">),</span> <span class="s1">&#39;Loss is NaN!&#39;</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="p">[</span><span class="n">meter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="k">for</span> <span class="n">meter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
            <span class="n">stats</span><span class="p">[</span><span class="s1">&#39;train_loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">stats</span></div>


<div class="viewcode-block" id="Trainer.val_loop">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.val_loop">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">val_loop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_preds</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute validation loop.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            return_preds (bool): Whether to return predictions</span>
<span class="sd">            max_batches (int, optional): Maximum number of batches to process</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            dict or tuple: Validation statistics, optionally with predictions and labels</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span>
        <span class="n">repeats</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">repeats</span> <span class="k">if</span> <span class="n">repeats</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">probe_preds</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">images</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_loader</span><span class="p">):</span>
                        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                        <span class="n">all_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

                        <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_fixations</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">n_fixations_val</span><span class="p">)</span> <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">n_fixations_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{}</span>
                        <span class="n">embeddings</span><span class="p">,</span> <span class="n">list_representation</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">setting</span><span class="o">=</span><span class="s1">&#39;supervised&#39;</span><span class="p">,</span> 
                                                                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                                                                <span class="p">)</span>

                        <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">no_probes</span><span class="p">:</span>
                            <span class="n">list_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">probes</span><span class="p">(</span><span class="n">list_representation</span><span class="p">)</span>
                            <span class="n">loss_classif</span> <span class="o">=</span> <span class="mf">0.</span>
                            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">)):</span>
                                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_layer_probes_only</span> <span class="ow">and</span> <span class="n">l</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                                    <span class="k">continue</span>
                                <span class="n">current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">target</span><span class="p">)</span>
                                <span class="n">loss_classif</span> <span class="o">+=</span> <span class="n">current_loss</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)](</span><span class="n">current_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                                <span class="n">meters</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;multilabel_acc_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;top_1_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">),</span> <span class="s1">&#39;top_5_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span>
                                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">meters</span><span class="p">:</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">list_outputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">target</span><span class="p">)</span>
                                <span class="k">if</span> <span class="sa">f</span><span class="s1">&#39;layer</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s1">&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">probe_preds</span><span class="p">:</span>
                                    <span class="n">probe_preds</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                                <span class="n">probe_preds</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;layer</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">list_outputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">:</span>

                            <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                        
                            <span class="n">current_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sup_loss</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_val&#39;</span><span class="p">](</span><span class="n">current_loss</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                            <span class="n">meters</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;multilabel_acc_val&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;top_1_val&#39;</span><span class="p">,</span> <span class="s1">&#39;top_5_val&#39;</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">meters</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="n">k</span><span class="p">](</span><span class="n">embeddings</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">target</span><span class="p">)</span>
                            
        <span class="n">stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">[</span><span class="n">meter</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span> <span class="k">for</span> <span class="n">meter</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">all_targets</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_targets</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">no_probes</span><span class="p">:</span>
            <span class="n">probe_preds</span> <span class="o">=</span> <span class="p">{</span><span class="n">layer</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">probe_preds_</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">probe_preds_</span> <span class="ow">in</span> <span class="n">probe_preds</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">do_roc</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">probe_preds_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">probe_preds</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
                    <span class="k">if</span> <span class="s1">&#39;multilabel&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span><span class="p">:</span>
                        <span class="n">use_targets</span> <span class="o">=</span> <span class="n">all_targets</span>
                        <span class="n">mtag</span> <span class="o">=</span> <span class="s1">&#39;multilabel_&#39;</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">use_targets</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">all_targets</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">probe_preds_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                        <span class="n">mtag</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
                    <span class="n">use_categ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">use_targets</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">use_targets</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>
                    <span class="k">for</span> <span class="n">average</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;weighted&#39;</span><span class="p">,</span> <span class="s1">&#39;macro&#39;</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span> <span class="ow">and</span> <span class="n">ii</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">probe_preds</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                            <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">use_targets</span><span class="p">[:,</span><span class="n">use_categ</span><span class="p">],</span> <span class="n">preds</span><span class="p">[:,</span><span class="n">use_categ</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">)</span>
                            <span class="n">stats</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">mtag</span><span class="si">}</span><span class="s1">roc_auc_</span><span class="si">{</span><span class="n">average</span><span class="si">}</span><span class="s1">_val_p0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span>
                        <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">use_targets</span><span class="p">[:,</span><span class="n">use_categ</span><span class="p">],</span> <span class="n">probe_preds_</span><span class="p">[:,</span><span class="n">use_categ</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">)</span>
                        <span class="n">stats</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">mtag</span><span class="si">}</span><span class="s1">roc_auc_</span><span class="si">{</span><span class="n">average</span><span class="si">}</span><span class="s1">_val_</span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">auc</span>
        
        <span class="k">if</span> <span class="n">return_preds</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supervised_loss</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_network_training</span><span class="p">:</span>
                <span class="c1"># classifier isn&#39;t being trained, so we want the probe predictions</span>
                <span class="n">preds</span> <span class="o">=</span> <span class="n">probe_preds</span>
            <span class="k">return</span> <span class="n">stats</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">all_targets</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">stats</span></div>


<div class="viewcode-block" id="Trainer.compute_activations">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.compute_activations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">compute_activations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">layer_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                            <span class="n">fixation_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                            <span class="n">area_range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">n_fixations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">apply_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">keep_fix_dim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                            <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dataset_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">max_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">setting</span><span class="o">=</span><span class="s1">&#39;supervised&#39;</span><span class="p">,</span>
                              <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                            <span class="p">):</span>
        <span class="k">if</span> <span class="n">fixation_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fixation_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">fixation_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span> <span class="ow">and</span> <span class="n">area_range</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fixation_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fixation_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">saccades</span><span class="o">.</span><span class="n">fixation_size_frac_val</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;fixation_size&#39;</span><span class="p">,</span> <span class="n">fixation_size</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;area_range&#39;</span><span class="p">,</span> <span class="n">area_range</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">phase</span> <span class="o">=</span><span class="s1">&#39;train&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">phase</span> <span class="o">=</span> <span class="s1">&#39;val&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">dset_tag</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s1">_&#39;</span> <span class="k">if</span> <span class="n">dataset_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">stag</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;_</span><span class="si">{</span><span class="n">setting</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">if</span> <span class="n">setting</span> <span class="o">!=</span> <span class="s1">&#39;supervised&#39;</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="n">layer_tag</span> <span class="o">=</span> <span class="n">layer_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s1">&#39;last&#39;</span>
        <span class="n">cache_fn</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">SLOW_DIR</span><span class="si">}</span><span class="s1">/activations/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">base_fn</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">dset_tag</span><span class="si">}{</span><span class="n">phase</span><span class="si">}</span><span class="s1">_fixsize-</span><span class="si">{</span><span class="n">fixation_size</span><span class="si">}</span><span class="s1">_arearange-</span><span class="si">{</span><span class="n">area_range</span><span class="si">}</span><span class="s1">_nfix-</span><span class="si">{</span><span class="n">n_fixations</span><span class="si">}</span><span class="s1">_layer-</span><span class="si">{</span><span class="n">layer_tag</span><span class="si">}{</span><span class="n">stag</span><span class="si">}</span><span class="s1">.pkl&#39;</span>
        <span class="k">if</span> <span class="n">Path</span><span class="p">(</span><span class="n">cache_fn</span><span class="p">)</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="n">cache</span><span class="p">:</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="n">return_images</span><span class="p">,</span> <span class="s2">&quot;return_images not supported when loading cached activations&quot;</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Loading cached activations from </span><span class="si">{</span><span class="n">cache_fn</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">all_activations</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">,</span> <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">cache_fn</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">all_activations</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">,</span> <span class="n">all_outputs</span>

        <span class="c1"># Set up hook-based activation capture</span>
        <span class="k">if</span> <span class="n">layer_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Default to the last layer if no layer name specified</span>
            <span class="n">available_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">list_available_layers</span><span class="p">()</span>
            <span class="c1"># Find the last MLP layer (typically the output layer)</span>
            <span class="n">mlp_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">available_layers</span> <span class="k">if</span> <span class="s1">&#39;fc_block&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">mlp_layers</span><span class="p">:</span>
                <span class="n">layer_name</span> <span class="o">=</span> <span class="n">mlp_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Last MLP layer</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">layer_name</span> <span class="o">=</span> <span class="n">available_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Last available layer</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No layer name specified, using default: </span><span class="si">{</span><span class="n">layer_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
        <span class="n">activation_hooks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">setup_activation_hooks</span><span class="p">(</span><span class="n">layer_name</span><span class="p">)</span>
        
        <span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_activations</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_images</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">all_fixated_images</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">amp_dtype</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="nb">bool</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">use_amp</span><span class="p">)):</span>
                    <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">loader</span><span class="p">)):</span>
                        <span class="k">if</span> <span class="n">ii</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">n_fixations</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">assert</span> <span class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;supervised&#39;</span><span class="p">,</span> <span class="s2">&quot;n_fixations only supported for supervised setting&quot;</span>

                        <span class="n">multi_fixations</span> <span class="o">=</span> <span class="n">setting</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;supervised&#39;</span><span class="p">,</span> <span class="s1">&#39;control_supervised&#39;</span><span class="p">]</span>
                        <span class="n">new_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_fixations</span><span class="o">=</span><span class="n">n_fixations</span><span class="p">,</span> <span class="n">do_postproc</span><span class="o">=</span><span class="ow">not</span> <span class="n">keep_fix_dim</span><span class="p">)</span> <span class="k">if</span> <span class="n">multi_fixations</span> <span class="k">else</span> <span class="p">{}</span>
                        <span class="n">kwargs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">new_kwargs</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sup_fixator</span><span class="p">,</span> <span class="s1">&#39;cached_saliency&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sup_fixator</span><span class="o">.</span><span class="n">cached_saliency</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;cache_inds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">ii</span> <span class="o">*</span> <span class="n">batch_size</span>
                        
                        <span class="c1"># Forward pass - hooks will capture activations automatically</span>
                        <span class="n">embeddings</span><span class="p">,</span> <span class="n">list_representation</span><span class="p">,</span> <span class="n">fixated_images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                                                                <span class="n">images</span><span class="p">,</span> 
                                                                <span class="n">setting</span><span class="o">=</span><span class="n">setting</span><span class="p">,</span>
                                                                <span class="n">fixation_size</span><span class="o">=</span><span class="n">fixation_size</span><span class="p">,</span>
                                                                <span class="n">area_range</span><span class="o">=</span><span class="n">area_range</span><span class="p">,</span>
                                                                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                                                                <span class="p">)</span>
                        
                        <span class="c1"># Get captured activations from hooks</span>
                        <span class="n">these_acts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">get_captured_activations</span><span class="p">(</span><span class="n">activation_hooks</span><span class="p">,</span> <span class="n">layer_name</span><span class="p">)</span>
                        <span class="n">all_activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">these_acts</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                        <span class="n">all_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                        
                        <span class="k">if</span> <span class="n">keep_fix_dim</span> <span class="ow">and</span> <span class="n">apply_head</span><span class="p">:</span>
                            <span class="c1"># apply head to each fixation independently</span>
                            <span class="n">these_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">embeddings</span><span class="p">[:,</span><span class="n">ii</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)])</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># head has already been applied over all fixations, or we are planning to apply it later</span>
                            <span class="n">these_outputs</span> <span class="o">=</span> <span class="n">embeddings</span>
                        <span class="k">if</span> <span class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;ssl&#39;</span><span class="p">:</span>
                            <span class="k">assert</span> <span class="ow">not</span> <span class="n">apply_head</span><span class="p">,</span> <span class="s2">&quot;SSL loss does not support head application&quot;</span>
                            <span class="n">these_outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">these_outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                        <span class="n">all_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">these_outputs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                        <span class="k">if</span> <span class="n">return_images</span><span class="p">:</span>
                            <span class="n">all_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fixated_images</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                                <span class="n">fixated_images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">fixated_images</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                            <span class="n">all_fixated_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fixated_images</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

                        <span class="k">if</span> <span class="n">max_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ii</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;=</span> <span class="n">max_batches</span><span class="p">:</span>
                            <span class="k">break</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="c1"># Clean up hooks</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">cleanup_activation_hooks</span><span class="p">(</span><span class="n">activation_hooks</span><span class="p">)</span>

        <span class="n">all_targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_targets</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;multi_fixations&#39;</span><span class="p">,</span> <span class="n">multi_fixations</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">setting</span> <span class="o">==</span> <span class="s1">&#39;ssl&#39;</span><span class="p">:</span>
            <span class="c1"># drop last batch if it has less elements</span>
            <span class="k">if</span> <span class="n">all_activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">all_activations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="n">all_activations</span> <span class="o">=</span> <span class="n">all_activations</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">all_outputs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">all_activations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_activations</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_activations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_activations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
            <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 

        <span class="k">if</span> <span class="n">cache</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Caching activations to </span><span class="si">{</span><span class="n">cache_fn</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">cache_fn</span><span class="p">)</span><span class="o">.</span><span class="n">parent</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">((</span><span class="n">all_activations</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">,</span> <span class="n">all_outputs</span><span class="p">),</span> <span class="nb">open</span><span class="p">(</span><span class="n">cache_fn</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">return_images</span><span class="p">:</span>
            <span class="n">all_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_images</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">all_fixated_images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">all_fixated_images</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">all_activations</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">,</span> <span class="n">all_outputs</span><span class="p">,</span> <span class="n">all_images</span><span class="p">,</span> <span class="n">all_fixated_images</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_activations</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">,</span> <span class="n">all_outputs</span></div>


<div class="viewcode-block" id="Trainer.initialize_logger">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.initialize_logger">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_logger</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize logging system and create log directory.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">folder</span><span class="p">:</span>
            <span class="n">folder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">folder</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;//&quot;</span><span class="p">,</span><span class="s2">&quot;/&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">folder</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">SAVE_DIR</span><span class="si">}</span><span class="s1">/logs/</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">base_fn</span><span class="si">}</span><span class="s1">&#39;</span>
        
        <span class="c1"># Set up meters for tracking metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">),</span>
            <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">no_probes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_probe_layers</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="o">==</span> <span class="s1">&#39;supervised_multilabel&#39;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;multilabel_acc_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multilabel&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;multilabel_acc_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multilabel&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;top_1_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multiclass&#39;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;top_5_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multiclass&#39;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;top_1_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multiclass&#39;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;top_5_val_layer&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multiclass&#39;</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>    
                    
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">Path</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="s1">&#39;/final_weights.pth&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">uid</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="n">folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">=</span> <span class="n">folder</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=&gt; Logging in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            
            <span class="c1"># Copy Hydra output files to our log directory</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">copy_hydra_outputs</span><span class="p">()</span>
            
            <span class="c1"># Save parameters to JSON file</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span> <span class="o">/</span> <span class="s1">&#39;params.json&#39;</span><span class="p">):</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">folder</span> <span class="o">/</span> <span class="s1">&#39;params.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w+&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
                    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span><span class="p">,</span> <span class="n">handle</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.copy_hydra_outputs">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.copy_hydra_outputs">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">copy_hydra_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Copy Hydra output files to our log directory.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">hydra_cfg</span> <span class="o">=</span> <span class="n">hydra</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">hydra_config</span><span class="o">.</span><span class="n">HydraConfig</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;skipping hydra directory copying&#39;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="n">hydra_output_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">hydra_cfg</span><span class="o">.</span><span class="n">run</span><span class="o">.</span><span class="n">dir</span><span class="p">)</span>
        
        <span class="c1"># Only copy if Hydra output directory is different from our log directory</span>
        <span class="k">if</span> <span class="n">hydra_output_dir</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="ow">and</span> <span class="n">hydra_output_dir</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="n">hydra_output_dir</span> <span class="o">/</span> <span class="s1">&#39;.hydra&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="s1">&#39;hydra&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Copying Hydra outputs from </span><span class="si">{</span><span class="n">hydra_output_dir</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

                            
<div class="viewcode-block" id="Trainer.initialize_remote_logger">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.initialize_remote_logger">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_remote_logger</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize remote logging (e.g., wandb) for experiment tracking.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">use_wandb</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
                <span class="n">project</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">wandb</span><span class="o">.</span><span class="n">project</span><span class="p">,</span>
                <span class="n">entity</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">wandb</span><span class="o">.</span><span class="n">entity</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">base_fn</span><span class="p">,</span>
                <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cfg_dict</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.log">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.log">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">log</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">content</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Log training/validation statistics.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            content (dict): Statistics to log</span>
<span class="sd">            phase (str): Phase name (&#39;train&#39; or &#39;val&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=&gt; Log (rank=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="si">}</span><span class="s1">): </span><span class="si">{</span><span class="n">content</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Log to wandb if enabled</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">use_wandb</span><span class="p">:</span>
                <span class="n">wandb</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">content</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            
            <span class="c1"># Log to file</span>
            <span class="n">log_file</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_folder</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s2">_log.json&quot;</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.exec">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.exec">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">exec</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">gpu</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Execute training with the given configuration.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            gpu (int): GPU device ID</span>
<span class="sd">            cfg (DictConfig): Training configuration</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create trainer instance</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">gpu</span><span class="p">,</span> <span class="n">cfg</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">eval_only</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">eval_and_log</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">cleanup_distributed</span><span class="p">()</span>

        <span class="c1"># Finish wandb logging</span>
        <span class="n">wandb</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="c1"># Write final statistics</span>
        <span class="n">iterations</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">final_stats</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">final_accuracy</span><span class="p">(</span><span class="n">iterations</span><span class="o">=</span><span class="n">iterations</span><span class="p">)</span>
        
        <span class="c1"># Save final stats to CSV files</span>
        <span class="k">for</span> <span class="n">dir_</span> <span class="ow">in</span> <span class="p">[</span><span class="n">SAVE_DIR</span><span class="p">,</span> <span class="n">SLOW_DIR</span><span class="p">]:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_</span><span class="si">}</span><span class="s2">/logs/</span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">base_fn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">final_stats</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_</span><span class="si">}</span><span class="s2">/logs/</span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">base_fn</span><span class="si">}</span><span class="s2">/final_stats.csv&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.launch_from_args">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.launch_from_args">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">launch_from_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Launch training with the given configuration.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            cfg (DictConfig): Training configuration</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="c1"># Distributed training setup</span>
            <span class="n">ngpus_per_node</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
            <span class="n">world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SLURM_NNODES&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">))</span> <span class="o">*</span> <span class="n">ngpus_per_node</span>                
            
            <span class="k">if</span> <span class="s2">&quot;SLURM_JOB_NODELIST&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
                <span class="n">cmd</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;scontrol&quot;</span><span class="p">,</span> <span class="s2">&quot;show&quot;</span><span class="p">,</span> <span class="s2">&quot;hostnames&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;SLURM_JOB_NODELIST&quot;</span><span class="p">)]</span>
                <span class="n">host_name</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">check_output</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">host_name</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span>

            <span class="n">dist_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;tcp://</span><span class="si">{</span><span class="n">host_name</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">port</span><span class="si">}</span><span class="s2">&quot;</span>
            
            <span class="c1"># Check if the current port is available, if not find a new one</span>
            <span class="n">current_port</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">dist</span><span class="o">.</span><span class="n">port</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">is_port_available</span><span class="p">(</span><span class="n">host_name</span><span class="p">,</span> <span class="n">current_port</span><span class="p">):</span>
                <span class="n">new_port</span> <span class="o">=</span> <span class="n">find_available_port</span><span class="p">(</span><span class="n">host_name</span><span class="p">)</span>
                <span class="n">dist_url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;tcp://</span><span class="si">{</span><span class="n">host_name</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">new_port</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Port </span><span class="si">{</span><span class="n">current_port</span><span class="si">}</span><span class="s2"> was not available, using port </span><span class="si">{</span><span class="n">new_port</span><span class="si">}</span><span class="s2"> instead&quot;</span><span class="p">)</span>
            
            <span class="c1"># Update config with computed values</span>
            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;dist.world_size&quot;</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;dist.ngpus&quot;</span><span class="p">,</span> <span class="n">ngpus_per_node</span><span class="p">)</span>
            <span class="n">OmegaConf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="s2">&quot;dist.dist_url&quot;</span><span class="p">,</span> <span class="n">dist_url</span><span class="p">)</span> 
            
            <span class="n">torch</span><span class="o">.</span><span class="n">multiprocessing</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">exec</span><span class="p">,</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">ngpus_per_node</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">cfg</span><span class="p">,))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Single GPU training</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">exec</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cfg</span><span class="p">)</span> <span class="c1"># Pass 0 for single GPU</span></div>


<div class="viewcode-block" id="Trainer.add_supervised_meters">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.add_supervised_meters">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">add_supervised_meters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add supervised training metrics for logging.&quot;&quot;&quot;</span>
        <span class="n">acc_type</span> <span class="o">=</span> <span class="s1">&#39;multilabel&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="o">==</span> <span class="s1">&#39;supervised_multilabel&#39;</span> <span class="k">else</span> <span class="s1">&#39;multiclass&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_trn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;loss_classif_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">MeanMetric</span><span class="p">(</span><span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_name</span> <span class="o">==</span> <span class="s1">&#39;supervised_multilabel&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;multilabel_acc_trn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multilabel&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;multilabel_acc_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="s1">&#39;multilabel&#39;</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;top_1_trn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">acc_type</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_meters</span><span class="p">[</span><span class="s1">&#39;top_5_trn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">acc_type</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;top_1_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">acc_type</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">val_meters</span><span class="p">[</span><span class="s1">&#39;top_5_val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torchmetrics</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">acc_type</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">compute_on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainer.final_accuracy">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.Trainer.final_accuracy">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">final_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute the final accuracy of the model by averaging over a number of iterations.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            iterations (int): Number of validation runs to average over</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            pd.DataFrame: DataFrame containing averaged validation statistics</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Temporarily set validation repeats to 1 for final accuracy computation</span>
        <span class="n">original_repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">repeats</span> <span class="o">=</span> <span class="mi">1</span>
        
        <span class="n">all_stats</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
            <span class="n">stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">val_loop</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">stats</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_stats</span><span class="p">:</span>
                    <span class="n">all_stats</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">all_stats</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
        
        <span class="c1"># Restore original repeats setting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">validation</span><span class="o">.</span><span class="n">repeats</span> <span class="o">=</span> <span class="n">original_repeats</span>
        
        <span class="n">all_stats</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_stats</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">all_stats</span> </div>
</div>

    

<span class="c1">################################</span>
<span class="c1">##### Some Miscs functions #####</span>
<span class="c1">################################</span>

<span class="k">def</span><span class="w"> </span><span class="nf">has_argument</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">arg_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if a function or method has a specific argument.</span>
<span class="sd">    </span>
<span class="sd">    :param func: The function or method to inspect.</span>
<span class="sd">    :param arg_name: Name of the argument to check for.</span>
<span class="sd">    :return: Boolean indicating whether the argument is in the function&#39;s signature.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">arg_name</span> <span class="ow">in</span> <span class="n">signature</span><span class="o">.</span><span class="n">parameters</span>


<span class="k">def</span><span class="w"> </span><span class="nf">check_scaler_scale</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
    <span class="c1"># try to solve NAN issue</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="s1">&#39;_scale&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">scaler</span><span class="o">.</span><span class="n">_scale</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">:</span>
        <span class="n">scaler</span><span class="o">.</span><span class="n">_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">_scale</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_init_file</span><span class="p">():</span>
    <span class="c1"># Init file must not exist, but it&#39;s parent dir must exist.</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">get_shared_folder</span><span class="p">()),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">init_file</span> <span class="o">=</span> <span class="n">get_shared_folder</span><span class="p">()</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span><span class="o">.</span><span class="n">hex</span><span class="si">}</span><span class="s2">_init&quot;</span>
    <span class="k">if</span> <span class="n">init_file</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">init_file</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">init_file</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_shared_folder</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
    <span class="n">user</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;USER&quot;</span><span class="p">)</span>
    
    <span class="c1"># Get the full path to the current script.</span>
    <span class="n">current_script_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span>

    <span class="c1"># Get the directory containing the current script.</span>
    <span class="n">current_script_directory</span> <span class="o">=</span> <span class="n">current_script_path</span><span class="o">.</span><span class="n">parent</span>

    <span class="c1"># Construct the path to the &#39;checkpoint&#39; directory in the same location as the current script.</span>
    <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">current_script_directory</span> <span class="o">/</span> <span class="s2">&quot;checkpoint&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;checkpoint_path: &quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span><span class="o">.</span><span class="n">is_dir</span><span class="p">())</span>
    
    <span class="k">if</span> <span class="n">Path</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">checkpoint_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">user</span><span class="si">}</span><span class="s2">/experiments&quot;</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;No shared folder available&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_from_checkpoint</span><span class="p">(</span><span class="n">base_fn</span><span class="p">,</span> <span class="n">new_head_and_probes</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">cfg</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">model_key</span> <span class="o">=</span> <span class="n">find_config</span><span class="p">(</span><span class="n">base_fn</span><span class="p">,</span> <span class="n">load</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">new_head_and_probes</span><span class="p">:</span>
        <span class="c1"># remove probes and head from state dict</span>
        <span class="k">if</span> <span class="s1">&#39;probes&#39;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;probes&#39;</span><span class="p">)</span>

        <span class="c1"># remove head from state dict</span>
        <span class="n">head_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="s1">&#39;head&#39;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">head_keys</span><span class="p">:</span>
            <span class="k">del</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">][</span><span class="n">key</span><span class="p">]</span>
        
        <span class="c1"># remove old FC layer if relevant</span>
        <span class="k">if</span> <span class="s1">&#39;fc.weight&#39;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">]:</span>
            <span class="k">del</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">][</span><span class="s1">&#39;fc.weight&#39;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">][</span><span class="s1">&#39;fc.bias&#39;</span><span class="p">]</span>

    <span class="n">new_base_fn</span> <span class="o">=</span> <span class="n">get_random_name</span><span class="p">()</span>
    <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;logging.pretrained.base_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">base_fn</span>
    <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;logging.base_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_base_fn</span>

    <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;logging.folder&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">SAVE_DIR</span><span class="si">}</span><span class="s1">/logs/</span><span class="si">{</span><span class="n">new_base_fn</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;logging.folder&#39;</span><span class="p">],</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;logging.log_level&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;training.from_checkpoint&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># replace some config params for new experiment but store old ones</span>
    <span class="k">for</span> <span class="n">kw</span><span class="p">,</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">kw</span> <span class="ow">in</span> <span class="n">cfg</span> <span class="ow">and</span> <span class="n">cfg</span><span class="p">[</span><span class="n">kw</span><span class="p">]</span> <span class="o">!=</span> <span class="n">arg</span><span class="p">:</span>
            <span class="n">cfg</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;pretrained.</span><span class="si">{</span><span class="n">kw</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="n">kw</span><span class="p">]</span>
        <span class="n">cfg</span><span class="p">[</span><span class="n">kw</span><span class="p">]</span> <span class="o">=</span> <span class="n">arg</span>

    <span class="c1"># save state dict to new base fn to ensure it gets loaded</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">SAVE_DIR</span><span class="si">}</span><span class="s1">/logs/</span><span class="si">{</span><span class="n">new_base_fn</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">SAVE_DIR</span><span class="si">}</span><span class="s1">/logs/</span><span class="si">{</span><span class="n">new_base_fn</span><span class="si">}</span><span class="s1">/model.pth&#39;</span><span class="p">)</span>

    <span class="c1"># Convert dict config to OmegaConf and launch</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
    <span class="n">Trainer</span><span class="o">.</span><span class="n">launch_from_args</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">is_port_available</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if a port is available on the given host.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span> <span class="k">as</span> <span class="n">sock</span><span class="p">:</span>
            <span class="n">sock</span><span class="o">.</span><span class="n">settimeout</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">sock</span><span class="o">.</span><span class="n">connect_ex</span><span class="p">((</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">result</span> <span class="o">!=</span> <span class="mi">0</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span><span class="w"> </span><span class="nf">find_available_port</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">start_port</span><span class="o">=</span><span class="mi">29500</span><span class="p">,</span> <span class="n">max_attempts</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Find an available port starting from start_port.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_attempts</span><span class="p">):</span>
        <span class="n">port</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">start_port</span><span class="p">,</span> <span class="n">start_port</span> <span class="o">+</span> <span class="mi">10000</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_port_available</span><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">port</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not find an available port after </span><span class="si">{</span><span class="n">max_attempts</span><span class="si">}</span><span class="s2"> attempts&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="load_config">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.load_config">[docs]</a>
<span class="nd">@add_to_all</span><span class="p">(</span><span class="n">__all__</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_config</span><span class="p">(</span><span class="n">base_fn</span><span class="p">,</span> <span class="n">load</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
    <span class="n">base_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">base_fn</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/hydra/config.yaml&#39;</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/hydra/config.yaml&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/config.yaml&#39;</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/config.yaml&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/params.json&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
        <span class="c1"># create the hydra config while we&#39;re at it</span>
        <span class="n">hydra_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/hydra&#39;</span>
        <span class="n">hydra_config_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">hydra_dir</span><span class="si">}</span><span class="s1">/config.yaml&#39;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">hydra_config_path</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">hydra_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">hydra_config_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_hydra</span><span class="p">:</span>
                <span class="n">OmegaConf</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">f_hydra</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">load</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/final_weights.pth&#39;</span><span class="p">):</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/final_weights.pth&#39;</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">model_key</span> <span class="o">=</span> <span class="s1">&#39;state_dict&#39;</span>
        <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/state_dict.pth&#39;</span><span class="p">):</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/state_dict.pth&#39;</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">model_key</span> <span class="o">=</span> <span class="s1">&#39;state_dict&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading non-final weights&#39;</span><span class="p">)</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">base_dir</span><span class="si">}</span><span class="s1">/model.pth&#39;</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">model_key</span> <span class="o">=</span> <span class="s1">&#39;model&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">model_key</span></div>



<div class="viewcode-block" id="find_config">
<a class="viewcode-back" href="../../api/foveation.trainer.html#foveation.trainer.find_config">[docs]</a>
<span class="nd">@add_to_all</span><span class="p">(</span><span class="n">__all__</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">find_config</span><span class="p">(</span><span class="n">base_fn</span><span class="p">,</span> <span class="n">load</span><span class="p">,</span> <span class="n">model_dirs</span><span class="o">=</span><span class="p">[</span><span class="n">SLOW_DIR</span><span class="p">,</span> <span class="n">SAVE_DIR</span><span class="p">],</span> <span class="n">subfolder</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">model_key</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="n">model_dirs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">subfolder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">folder</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">folder</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">subfolder</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">cfg</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">model_key</span> <span class="o">=</span> <span class="n">load_config</span><span class="p">(</span><span class="n">base_fn</span><span class="p">,</span> <span class="n">load</span><span class="p">,</span> <span class="n">folder</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="k">continue</span>
    <span class="k">if</span> <span class="n">cfg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Model with base_fn </span><span class="si">{</span><span class="n">base_fn</span><span class="si">}</span><span class="s1"> not found&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">model_key</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
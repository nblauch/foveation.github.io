

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>foveation.utils.fastaugs.functional_tensor &mdash; foveation 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=01f34227"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="foveation.utils.fastaugs.loader" href="foveation.utils.fastaugs.loader.html" />
    <link rel="prev" title="foveation.utils.fastaugs.functional" href="foveation.utils.fastaugs.functional.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            foveation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../read_me.html">A biologically-inspired foveated interface for deep vision models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Example notebooks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Core Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="foveation.sensing.html">foveation.sensing package</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.arch.html">foveation.arch package</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.saccadenet.html">foveation.saccadenet</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.trainer.html">foveation.trainer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Utilities &amp; Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="foveation.utils.html">foveation.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.demo.html">foveation.demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.paths.html">foveation.paths</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.probes.html">foveation.probes</a></li>
<li class="toctree-l1"><a class="reference internal" href="foveation.visualizer.html">foveation.visualizer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">foveation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="foveation.utils.html">foveation.utils package</a></li>
      <li class="breadcrumb-item active">foveation.utils.fastaugs.functional_tensor</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/foveation.utils.fastaugs.functional_tensor.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-foveation.utils.fastaugs.functional_tensor">
<span id="foveation-utils-fastaugs-functional-tensor"></span><h1>foveation.utils.fastaugs.functional_tensor<a class="headerlink" href="#module-foveation.utils.fastaugs.functional_tensor" title="Link to this heading"></a></h1>
<p>Lighted edited from <a class="reference external" href="https://github.com/pytorch/vision/blob/main/torchvision/transforms/functional_tensor.py">https://github.com/pytorch/vision/blob/main/torchvision/transforms/functional_tensor.py</a></p>
<p>Modified that I can make a small tweak to enable transforms over image batches to work with
different parameters for each image. Ultimately this enables me to perform these transforms
on the GPU, which is faster.</p>
<dl class="py class">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">Tensor</span></span><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorBase</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor._clear_non_serializable_cached_data">
<span class="sig-name descname"><span class="pre">_clear_non_serializable_cached_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor._clear_non_serializable_cached_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor._clear_non_serializable_cached_data" title="Link to this definition"></a></dt>
<dd><p>Clears any data cached in the tensor’s <code class="docutils literal notranslate"><span class="pre">__dict__</span></code> that would prevent the tensor
from being serialized.</p>
<p>For example, subclasses with custom dispatched sizes / strides cache this info in
non-serializable PyCapsules within the <code class="docutils literal notranslate"><span class="pre">__dict__</span></code>, and this must be cleared out for
serialization to function.</p>
<p>Any subclass that overrides this MUST call <code class="docutils literal notranslate"><span class="pre">super()._clear_non_serializable_cached_data().</span></code>
Additional data cleared within the override must be able to be re-cached transparently
to avoid breaking subclass functionality.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.align_to">
<span class="sig-name descname"><span class="pre">align_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.align_to"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.align_to" title="Link to this definition"></a></dt>
<dd><p>Permutes the dimensions of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor to match the order
specified in <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code>, adding size-one dims for any new names.</p>
<p>All of the dims of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> must be named in order to use this method.
The resulting tensor is a view on the original tensor.</p>
<p>All dimension names of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> must be present in <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code>.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code> may contain additional names that are not in <code class="docutils literal notranslate"><span class="pre">self.names</span></code>;
the output tensor has a size-one dimension for each of those new names.</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code> may contain up to one Ellipsis (<code class="docutils literal notranslate"><span class="pre">...</span></code>).
The Ellipsis is expanded to be equal to all dimension names of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>
that are not mentioned in <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code>, in the order that they appear
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>Python 2 does not support Ellipsis but one may use a string literal
instead (<code class="docutils literal notranslate"><span class="pre">'...'</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>names</strong> (<em>iterable</em><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – The desired dimension ordering of the
output tensor. May contain up to one Ellipsis that is expanded
to all unmentioned dim names of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">named_tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">)</span>

<span class="go"># Move the F and E dims to the front while keeping the rest in order</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">named_tensor</span><span class="o">.</span><span class="n">align_to</span><span class="p">(</span><span class="s1">&#39;F&#39;</span><span class="p">,</span> <span class="s1">&#39;E&#39;</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The named tensor API is experimental and subject to change.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">create_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.backward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.backward" title="Link to this definition"></a></dt>
<dd><p>Computes the gradient of current tensor wrt graph leaves.</p>
<p>The graph is differentiated using the chain rule. If the tensor is
non-scalar (i.e. its data has more than one element) and requires
gradient, the function additionally requires specifying a <code class="docutils literal notranslate"><span class="pre">gradient</span></code>.
It should be a tensor of matching type and shape, that represents
the gradient of the differentiated function w.r.t. <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>This function accumulates gradients in the leaves - you might need to zero
<code class="docutils literal notranslate"><span class="pre">.grad</span></code> attributes or set them to <code class="docutils literal notranslate"><span class="pre">None</span></code> before calling it.
See <a class="reference external" href="https://docs.pytorch.org/docs/stable/autograd.html#default-grad-layouts" title="(in PyTorch v2.8)"><span class="xref std std-ref">Default gradient layouts</span></a>
for details on the memory layout of accumulated gradients.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you run any forward ops, create <code class="docutils literal notranslate"><span class="pre">gradient</span></code>, and/or call <code class="docutils literal notranslate"><span class="pre">backward</span></code>
in a user-specified CUDA stream context, see
<a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/cuda.html#bwd-cuda-stream-semantics" title="(in PyTorch v2.8)"><span class="xref std std-ref">Stream semantics of backward passes</span></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are provided and a given input is not a leaf,
the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).
It is an implementation detail on which the user should not rely.
See <a class="reference external" href="https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780">https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780</a> for more details.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – The gradient of the function
being differentiated w.r.t. <code class="docutils literal notranslate"><span class="pre">self</span></code>.
This argument can be omitted if <code class="docutils literal notranslate"><span class="pre">self</span></code> is a scalar. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>retain_graph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, the graph used to compute the grads will be freed;
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, it will be retained. The default is <code class="docutils literal notranslate"><span class="pre">None</span></code>, in which case the value is inferred from <code class="docutils literal notranslate"><span class="pre">create_graph</span></code>
(i.e., the graph is retained only when higher-order derivative tracking is requested). Note that in nearly all cases
setting this option to True is not needed and often can be worked around in a much more efficient way.</p></li>
<li><p><strong>create_graph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, graph of the derivative will
be constructed, allowing to compute higher order derivative
products. Defaults to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>inputs</strong> (<em>Sequence</em><em>[</em><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a><em>]</em><em>, </em><em>optional</em>) – Inputs w.r.t. which the gradient will be
accumulated into <code class="docutils literal notranslate"><span class="pre">.grad</span></code>. All other tensors will be ignored. If not
provided, the gradient is accumulated into all the leaf Tensors that were
used to compute the <code class="xref py py-attr docutils literal notranslate"><span class="pre">tensors</span></code>. Defaults to <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.detach">
<span class="sig-name descname"><span class="pre">detach</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.detach" title="Link to this definition"></a></dt>
<dd><p>Returns a new Tensor, detached from the current graph.</p>
<p>The result will never require gradient.</p>
<p>This method also affects forward mode AD gradients and the result will never
have forward mode AD gradients.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Returned Tensor shares the same storage with the original one.
In-place modifications on either of them will be seen, and may trigger
errors in correctness checks.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.detach_">
<span class="sig-name descname"><span class="pre">detach_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.detach_" title="Link to this definition"></a></dt>
<dd><p>Detaches the Tensor from the graph that created it, making it a leaf.
Views cannot be detached in-place.</p>
<p>This method also affects forward mode AD gradients and the result will never
have forward mode AD gradients.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.dim_order">
<span class="sig-name descname"><span class="pre">dim_order</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ambiguity_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><span class="pre">tuple</span></a></span></span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.dim_order"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.dim_order" title="Link to this definition"></a></dt>
<dd><p>Returns the uniquely determined tuple of int describing the dim order or
physical layout of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>The dim order represents how dimensions are laid out in memory of dense tensors,
starting from the outermost to the innermost dimension.</p>
<p>Note that the dim order may not always be uniquely determined.
If <cite>ambiguity_check</cite> is True, this function raises a RuntimeError when the dim order cannot be uniquely determined;
If <cite>ambiguity_check</cite> is a list of memory formats, this function raises a RuntimeError when tensor can not be interpreted
into exactly one of the given memory formats, or it cannot be uniquely determined.
If <cite>ambiguity_check</cite> is False, it will return one of legal dim order(s) without checking its uniqueness.
Otherwise, it will raise TypeError.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>ambiguity_check</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em> or </em><em>List</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.memory_format" title="(in PyTorch v2.8)"><em>torch.memory_format</em></a><em>]</em>) – The check method for ambiguity of dim order.</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span><span class="o">.</span><span class="n">dim_order</span><span class="p">()</span>
<span class="go">(0, 1, 2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">dim_order</span><span class="p">()</span>
<span class="go">(0, 2, 1, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">channels_last</span><span class="p">)</span><span class="o">.</span><span class="n">dim_order</span><span class="p">()</span>
<span class="go">(0, 2, 3, 1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">dim_order</span><span class="p">()</span>
<span class="go">(0, 1, 2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">dim_order</span><span class="p">(</span><span class="n">ambiguity_check</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="go">The tensor does not have unique dim order, or cannot map to exact one of the given memory formats.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">dim_order</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">ambiguity_check</span><span class="o">=</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">contiguous_format</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">channels_last</span><span class="p">]</span>
<span class="gp">... </span><span class="p">)</span>  <span class="c1"># It can be mapped to contiguous format</span>
<span class="go">(0, 1, 2, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">try</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">dim_order</span><span class="p">(</span><span class="n">ambiguity_check</span><span class="o">=</span><span class="s2">&quot;ILLEGAL&quot;</span><span class="p">)</span>
<span class="gp">... </span><span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="go">The ambiguity_check argument must be a bool or a list of memory formats.</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The dim_order tensor API is experimental and subject to change.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.eig">
<span class="sig-name descname"><span class="pre">eig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eigenvectors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.eig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.eig" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.is_shared">
<span class="sig-name descname"><span class="pre">is_shared</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.is_shared"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.is_shared" title="Link to this definition"></a></dt>
<dd><p>Checks if tensor is in shared memory.</p>
<p>This is always <code class="docutils literal notranslate"><span class="pre">True</span></code> for CUDA tensors.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.istft">
<span class="sig-name descname"><span class="pre">istft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_fft</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">win_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onesided</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_complex</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.istft"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.istft" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.istft.html#torch.istft" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.istft()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.lstsq">
<span class="sig-name descname"><span class="pre">lstsq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.lstsq"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.lstsq" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.lu">
<span class="sig-name descname"><span class="pre">lu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pivot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">get_infos</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.lu"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.lu" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.lu.html#torch.lu" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lu()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.module_load">
<span class="sig-name descname"><span class="pre">module_load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.module_load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.module_load" title="Link to this definition"></a></dt>
<dd><p>Defines how to transform <code class="docutils literal notranslate"><span class="pre">other</span></code> when loading it into <code class="docutils literal notranslate"><span class="pre">self</span></code> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code>.</p>
<p>Used when <a class="reference external" href="https://docs.pytorch.org/docs/stable/future_mod.html#torch.__future__.get_swap_module_params_on_conversion" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_swap_module_params_on_conversion()</span></code></a> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>It is expected that <code class="docutils literal notranslate"><span class="pre">self</span></code> is a parameter or buffer in an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> and <code class="docutils literal notranslate"><span class="pre">other</span></code> is the
value in the state dictionary with the corresponding key, this method defines
how <code class="docutils literal notranslate"><span class="pre">other</span></code> is remapped before being swapped with <code class="docutils literal notranslate"><span class="pre">self</span></code> via
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.utils.swap_tensors.html#torch.utils.swap_tensors" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">swap_tensors()</span></code></a> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method should always return a new object that is not <code class="docutils literal notranslate"><span class="pre">self</span></code> or <code class="docutils literal notranslate"><span class="pre">other</span></code>.
For example, the default implementation returns <code class="docutils literal notranslate"><span class="pre">self.copy_(other).detach()</span></code>
if <code class="docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or <code class="docutils literal notranslate"><span class="pre">other.detach()</span></code> if <code class="docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>other</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a>) – value in state dict with key corresponding to <code class="docutils literal notranslate"><span class="pre">self</span></code></p></li>
<li><p><strong>assign</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a>) – the assign argument passed to <code class="xref py py-meth docutils literal notranslate"><span class="pre">nn.Module.load_state_dict()</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.norm">
<span class="sig-name descname"><span class="pre">norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fro'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keepdim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.norm" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.norm()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.refine_names">
<span class="sig-name descname"><span class="pre">refine_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.refine_names"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.refine_names" title="Link to this definition"></a></dt>
<dd><p>Refines the dimension names of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> according to <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code>.</p>
<p>Refining is a special case of renaming that “lifts” unnamed dimensions.
A <code class="docutils literal notranslate"><span class="pre">None</span></code> dim can be refined to have any name; a named dim can only be
refined to have the same name.</p>
<p>Because named tensors can coexist with unnamed tensors, refining names
gives a nice way to write named-tensor-aware code that works with both
named and unnamed tensors.</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code> may contain up to one Ellipsis (<code class="docutils literal notranslate"><span class="pre">...</span></code>).
The Ellipsis is expanded greedily; it is expanded in-place to fill
<code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code> to the same length as <code class="docutils literal notranslate"><span class="pre">self.dim()</span></code> using names from the
corresponding indices of <code class="docutils literal notranslate"><span class="pre">self.names</span></code>.</p>
<p>Python 2 does not support Ellipsis but one may use a string literal
instead (<code class="docutils literal notranslate"><span class="pre">'...'</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>names</strong> (<em>iterable</em><em> of </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – The desired names of the output tensor. May
contain up to one Ellipsis.</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">imgs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">named_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">named_imgs</span><span class="o">.</span><span class="n">names</span>
<span class="go">(&#39;N&#39;, &#39;C&#39;, &#39;H&#39;, &#39;W&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">refine_names</span><span class="p">(</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span><span class="o">.</span><span class="n">names</span>
<span class="go">(&#39;A&#39;, None, None, &#39;B&#39;, &#39;C&#39;)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The named tensor API is experimental and subject to change.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.register_hook">
<span class="sig-name descname"><span class="pre">register_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.register_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.register_hook" title="Link to this definition"></a></dt>
<dd><p>Registers a backward hook.</p>
<p>The hook will be called every time a gradient with respect to the
Tensor is computed. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The hook should not modify its argument, but it can optionally return
a new gradient which will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad</span></code>.</p>
<p>This function returns a handle with a method <code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code>
that removes the hook from the module.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/autograd.html#backward-hooks-execution" title="(in PyTorch v2.8)"><span>Backward Hooks execution</span></a> for more information on how when this hook
is executed, and how its execution is ordered relative to other hooks.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="k">lambda</span> <span class="n">grad</span><span class="p">:</span> <span class="n">grad</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># double the gradient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span><span class="o">.</span><span class="n">grad</span>

<span class="go"> 2</span>
<span class="go"> 4</span>
<span class="go"> 6</span>
<span class="go">[torch.FloatTensor of size (3,)]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>  <span class="c1"># removes the hook</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.register_post_accumulate_grad_hook">
<span class="sig-name descname"><span class="pre">register_post_accumulate_grad_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.register_post_accumulate_grad_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.register_post_accumulate_grad_hook" title="Link to this definition"></a></dt>
<dd><p>Registers a backward hook that runs after grad accumulation.</p>
<p>The hook will be called after all gradients for a tensor have been accumulated,
meaning that the .grad field has been updated on that tensor. The post
accumulate grad hook is ONLY applicable for leaf tensors (tensors without a
.grad_fn field). Registering this hook on a non-leaf tensor will error!</p>
<p>The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">param</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</pre></div>
</div>
<p>Note that, unlike other autograd hooks, this hook operates on the tensor
that requires grad and not the grad itself. The hook can in-place modify
and access its Tensor argument, including its .grad field.</p>
<p>This function returns a handle with a method <code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code>
that removes the hook from the module.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/autograd.html#backward-hooks-execution" title="(in PyTorch v2.8)"><span>Backward Hooks execution</span></a> for more information on how when this hook
is executed, and how its execution is ordered relative to other hooks. Since
this hook runs during the backward pass, it will run in no_grad mode (unless
create_graph is True). You can use torch.enable_grad() to re-enable autograd
within the hook if you need it.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># simulate a simple SGD update</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">register_post_accumulate_grad_hook</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=-</span><span class="n">lr</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>
<span class="go">tensor([-0.0100, -0.0200, -0.0300], requires_grad=True)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>  <span class="c1"># removes the hook</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.reinforce">
<span class="sig-name descname"><span class="pre">reinforce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.reinforce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.reinforce" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.rename">
<span class="sig-name descname"><span class="pre">rename</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">rename_map</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.rename"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.rename" title="Link to this definition"></a></dt>
<dd><p>Renames dimension names of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p>
<p>There are two main usages:</p>
<p><code class="docutils literal notranslate"><span class="pre">self.rename(**rename_map)</span></code> returns a view on tensor that has dims
renamed as specified in the mapping <code class="xref py py-attr docutils literal notranslate"><span class="pre">rename_map</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">self.rename(*names)</span></code> returns a view on tensor, renaming all
dimensions positionally using <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code>.
Use <code class="docutils literal notranslate"><span class="pre">self.rename(None)</span></code> to drop names on a tensor.</p>
<p>One cannot specify both positional args <code class="xref py py-attr docutils literal notranslate"><span class="pre">names</span></code> and keyword args
<code class="xref py py-attr docutils literal notranslate"><span class="pre">rename_map</span></code>.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">imgs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;H&#39;</span><span class="p">,</span> <span class="s1">&#39;W&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="s1">&#39;channels&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span><span class="o">.</span><span class="n">names</span>
<span class="go">(&#39;batch&#39;, &#39;channels&#39;, &#39;H&#39;, &#39;W&#39;)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span><span class="o">.</span><span class="n">names</span>
<span class="go">(None, None, None, None)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="s1">&#39;channel&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">renamed_imgs</span><span class="o">.</span><span class="n">names</span>
<span class="go">(&#39;batch&#39;, &#39;channel&#39;, &#39;height&#39;, &#39;width&#39;)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The named tensor API is experimental and subject to change.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.rename_">
<span class="sig-name descname"><span class="pre">rename_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">names</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">rename_map</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.rename_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.rename_" title="Link to this definition"></a></dt>
<dd><p>In-place version of <a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor.rename" title="foveation.utils.fastaugs.functional_tensor.Tensor.rename"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rename()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.resize">
<span class="sig-name descname"><span class="pre">resize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.resize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.resize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.resize_as">
<span class="sig-name descname"><span class="pre">resize_as</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.resize_as"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.resize_as" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.share_memory_">
<span class="sig-name descname"><span class="pre">share_memory_</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.share_memory_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.share_memory_" title="Link to this definition"></a></dt>
<dd><p>Moves the underlying storage to shared memory.</p>
<p>This is a no-op if the underlying storage is already in shared memory
and for CUDA tensors. Tensors in shared memory cannot be resized.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/storage.html#torch.UntypedStorage.share_memory_" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.UntypedStorage.share_memory_()</span></code></a> for more details.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.solve">
<span class="sig-name descname"><span class="pre">solve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.solve"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.solve" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.split">
<span class="sig-name descname"><span class="pre">split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">split_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.split"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.split" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.split.html#torch.split" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.split()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.stft">
<span class="sig-name descname"><span class="pre">stft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_fft</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">win_length</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'reflect'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onesided</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_complex</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_to_window</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.stft"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.stft" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.stft.html#torch.stft" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.stft()</span></code></a></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This function changed signature at version 0.4.1. Calling with
the previous signature may cause error or return incorrect result.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.storage">
<span class="sig-name descname"><span class="pre">storage</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.pytorch.org/docs/stable/storage.html#torch.TypedStorage" title="(in PyTorch v2.8)"><span class="pre">torch.TypedStorage</span></a></span></span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.storage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.storage" title="Link to this definition"></a></dt>
<dd><p>Returns the underlying <code class="xref py py-class docutils literal notranslate"><span class="pre">TypedStorage</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="xref py py-class docutils literal notranslate"><span class="pre">TypedStorage</span></code> is deprecated. It will be removed in the future, and
<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code> will be the only storage class. To access the
<code class="xref py py-class docutils literal notranslate"><span class="pre">UntypedStorage</span></code> directly, use <code class="xref py py-attr docutils literal notranslate"><span class="pre">Tensor.untyped_storage()</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.storage_type">
<span class="sig-name descname"><span class="pre">storage_type</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.14)"><span class="pre">type</span></a></span></span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.storage_type"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.storage_type" title="Link to this definition"></a></dt>
<dd><p>Returns the type of the underlying storage.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.symeig">
<span class="sig-name descname"><span class="pre">symeig</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eigenvectors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.symeig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.symeig" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.to_sparse_coo">
<span class="sig-name descname"><span class="pre">to_sparse_coo</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.to_sparse_coo"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.to_sparse_coo" title="Link to this definition"></a></dt>
<dd><p>Convert a tensor to <a class="reference external" href="https://docs.pytorch.org/docs/stable/sparse.html#sparse-coo-docs" title="(in PyTorch v2.8)"><span class="xref std std-ref">coordinate format</span></a>.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dense</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse</span> <span class="o">=</span> <span class="n">dense</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sparse</span><span class="o">.</span><span class="n">_nnz</span><span class="p">()</span>
<span class="go">25</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.unflatten">
<span class="sig-name descname"><span class="pre">unflatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sizes</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.unflatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.unflatten" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.unflatten.html#torch.unflatten" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.unflatten()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.unique">
<span class="sig-name descname"><span class="pre">unique</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sorted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_counts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.unique"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.unique" title="Link to this definition"></a></dt>
<dd><p>Returns the unique elements of the input tensor.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.unique.html#torch.unique" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.unique()</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.Tensor.unique_consecutive">
<span class="sig-name descname"><span class="pre">unique_consecutive</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">return_inverse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_counts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/torch/_tensor.html#Tensor.unique_consecutive"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.Tensor.unique_consecutive" title="Link to this definition"></a></dt>
<dd><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.unique_consecutive.html#torch.unique_consecutive" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.unique_consecutive()</span></code></a></p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.grid_sample">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">grid_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/torch/nn/functional.html#grid_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.grid_sample" title="Link to this definition"></a></dt>
<dd><p>Compute grid sample.</p>
<p>Given an <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and a flow-field <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code>, computes the
<code class="docutils literal notranslate"><span class="pre">output</span></code> using <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> values and pixel locations from <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code>.</p>
<p>Currently, only spatial (4-D) and volumetric (5-D) <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> are
supported.</p>
<p>In the spatial (4-D) case, for <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with shape
<span class="math notranslate nohighlight">\((N, C, H_\text{in}, W_\text{in})\)</span> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> with shape
<span class="math notranslate nohighlight">\((N, H_\text{out}, W_\text{out}, 2)\)</span>, the output will have shape
<span class="math notranslate nohighlight">\((N, C, H_\text{out}, W_\text{out})\)</span>.</p>
<p>For each output location <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>, the size-2 vector
<code class="docutils literal notranslate"><span class="pre">grid[n,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> specifies <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> pixel locations <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>,
which are used to interpolate the output value <code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>.
In the case of 5D inputs, <code class="docutils literal notranslate"><span class="pre">grid[n,</span> <span class="pre">d,</span> <span class="pre">h,</span> <span class="pre">w]</span></code> specifies the
<code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z</span></code> pixel locations for interpolating
<code class="docutils literal notranslate"><span class="pre">output[n,</span> <span class="pre">:,</span> <span class="pre">d,</span> <span class="pre">h,</span> <span class="pre">w]</span></code>. <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code> argument specifies <code class="docutils literal notranslate"><span class="pre">nearest</span></code> or
<code class="docutils literal notranslate"><span class="pre">bilinear</span></code> interpolation method to sample the input pixels.</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> specifies the sampling pixel locations normalized by the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> spatial dimensions. Therefore, it should have most values in
the range of <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>. For example, values <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">-1,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">-1</span></code> is the
left-top pixel of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, and values  <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">1,</span> <span class="pre">y</span> <span class="pre">=</span> <span class="pre">1</span></code> is the
right-bottom pixel of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> has values outside the range of <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>, the corresponding
outputs are handled as defined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_mode</span></code>. Options are</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode=&quot;zeros&quot;</span></code>: use <code class="docutils literal notranslate"><span class="pre">0</span></code> for out-of-bound grid locations,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode=&quot;border&quot;</span></code>: use border values for out-of-bound grid locations,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding_mode=&quot;reflection&quot;</span></code>: use values at locations reflected by
the border for out-of-bound grid locations. For location far away
from the border, it will keep being reflected until becoming in bound,
e.g., (normalized) pixel location <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">-3.5</span></code> reflects by border <code class="docutils literal notranslate"><span class="pre">-1</span></code>
and becomes <code class="docutils literal notranslate"><span class="pre">x'</span> <span class="pre">=</span> <span class="pre">1.5</span></code>, then reflects by border <code class="docutils literal notranslate"><span class="pre">1</span></code> and becomes
<code class="docutils literal notranslate"><span class="pre">x''</span> <span class="pre">=</span> <span class="pre">-0.5</span></code>.</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function is often used in conjunction with <code class="xref py py-func docutils literal notranslate"><span class="pre">affine_grid()</span></code>
to build <a class="reference external" href="https://arxiv.org/abs/1506.02025">Spatial Transformer Networks</a> .</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using the CUDA backend, this operation may induce nondeterministic
behaviour in its backward pass that is not easily switched off.
Please see the notes on <span class="xref std std-doc">/notes/randomness</span> for background.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>NaN values in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grid</span></code> would be interpreted as <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a>) – input of shape <span class="math notranslate nohighlight">\((N, C, H_\text{in}, W_\text{in})\)</span> (4-D case)
or <span class="math notranslate nohighlight">\((N, C, D_\text{in}, H_\text{in}, W_\text{in})\)</span> (5-D case)</p></li>
<li><p><strong>grid</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a>) – flow-field of shape <span class="math notranslate nohighlight">\((N, H_\text{out}, W_\text{out}, 2)\)</span> (4-D case)
or <span class="math notranslate nohighlight">\((N, D_\text{out}, H_\text{out}, W_\text{out}, 3)\)</span> (5-D case)</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – interpolation mode to calculate output values
<code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>
Note: <code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code> supports only 4-D input.
When <code class="docutils literal notranslate"><span class="pre">mode='bilinear'</span></code> and the input is 5-D, the interpolation mode
used internally will actually be trilinear. However, when the input is 4-D,
the interpolation mode will legitimately be bilinear.</p></li>
<li><p><strong>padding_mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – padding mode for outside grid values
<code class="docutils literal notranslate"><span class="pre">'zeros'</span></code> | <code class="docutils literal notranslate"><span class="pre">'border'</span></code> | <code class="docutils literal notranslate"><span class="pre">'reflection'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'zeros'</span></code></p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Geometrically, we consider the pixels of the
input  as squares rather than points.
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the extrema (<code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>) are considered as referring
to the center points of the input’s corner pixels. If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, they
are instead considered as referring to the corner points of the input’s corner
pixels, making the sampling more resolution agnostic.
This option parallels the <code class="docutils literal notranslate"><span class="pre">align_corners</span></code> option in
<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.interpolate" title="foveation.utils.fastaugs.functional_tensor.interpolate"><code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code></a>, and so whichever option is used here
should also be used there to resize the input image before grid sampling.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>output Tensor</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>output (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor">Tensor</a>)</p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">True</span></code>, the grid positions depend on the pixel
size relative to the input image size, and so the locations sampled by
<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.grid_sample" title="foveation.utils.fastaugs.functional_tensor.grid_sample"><code class="xref py py-func docutils literal notranslate"><span class="pre">grid_sample()</span></code></a> will differ for the same input given at different
resolutions (that is, after being upsampled or downsampled).
The default behavior up to version 1.2.0 was <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">True</span></code>.
Since then, the default behavior has been changed to <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">False</span></code>,
in order to bring it in line with the default for <a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.interpolate" title="foveation.utils.fastaugs.functional_tensor.interpolate"><code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code> is implemented using the <a class="reference external" href="https://en.wikipedia.org/wiki/Bicubic_interpolation">cubic convolution algorithm</a> with <span class="math notranslate nohighlight">\(\alpha=-0.75\)</span>.
The constant <span class="math notranslate nohighlight">\(\alpha\)</span> might be different from packages to packages.
For example, <a class="reference external" href="https://github.com/python-pillow/Pillow/blob/4634eafe3c695a014267eefdce830b4a825beed7/src/libImaging/Resample.c#L51">PIL</a> and <a class="reference external" href="https://github.com/opencv/opencv/blob/f345ed564a06178670750bad59526cfa4033be55/modules/imgproc/src/resize.cpp#L908">OpenCV</a> use -0.5 and -0.75 respectively.
This algorithm may “overshoot” the range of values it’s interpolating.
For example, it may produce negative values or values greater than 255 when interpolating input in [0, 255].
Clamp the results with <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.clamp()</span></code></a> to ensure they are within the valid range.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.conv2d">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.conv2d" title="Link to this definition"></a></dt>
<dd><p>Applies a 2D convolution over an input image composed of several input
planes.</p>
<p>This operator supports <a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere" title="(in PyTorch v2.8)"><span class="xref std std-ref">TensorFloat32</span></a>.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a> for details and output shape.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span> <span class="pre">True</span></code>. See <span class="xref std std-doc">/notes/randomness</span> for more information.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operator supports complex data types i.e. <code class="docutils literal notranslate"><span class="pre">complex32,</span> <span class="pre">complex64,</span> <span class="pre">complex128</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> – input tensor of shape <span class="math notranslate nohighlight">\((\text{minibatch} , \text{in\_channels} , iH , iW)\)</span></p></li>
<li><p><strong>weight</strong> – filters of shape <span class="math notranslate nohighlight">\((\text{out\_channels} , \frac{\text{in\_channels}}{\text{groups}} , kH , kW)\)</span></p></li>
<li><p><strong>bias</strong> – optional bias tensor of shape <span class="math notranslate nohighlight">\((\text{out\_channels})\)</span>. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>stride</strong> – the stride of the convolving kernel. Can be a single number or a
tuple <cite>(sH, sW)</cite>. Default: 1</p></li>
<li><p><strong>padding</strong> – <p>implicit paddings on both sides of the input. Can be a string {‘valid’, ‘same’},
single number or a tuple <cite>(padH, padW)</cite>. Default: 0
<code class="docutils literal notranslate"><span class="pre">padding='valid'</span></code> is the same as no padding. <code class="docutils literal notranslate"><span class="pre">padding='same'</span></code> pads
the input so the output has the same shape as the input. However, this mode
doesn’t support any stride values other than 1.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For <code class="docutils literal notranslate"><span class="pre">padding='same'</span></code>, if the <code class="docutils literal notranslate"><span class="pre">weight</span></code> is even-length and
<code class="docutils literal notranslate"><span class="pre">dilation</span></code> is odd in any dimension, a full <a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.pad" title="foveation.utils.fastaugs.functional_tensor.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">pad()</span></code></a> operation
may be needed internally. Lowering performance.</p>
</div>
</p></li>
<li><p><strong>dilation</strong> – the spacing between kernel elements. Can be a single number or
a tuple <cite>(dH, dW)</cite>. Default: 1</p></li>
<li><p><strong>groups</strong> – split input into groups, both <span class="math notranslate nohighlight">\(\text{in\_channels}\)</span> and <span class="math notranslate nohighlight">\(\text{out\_channels}\)</span>
should be divisible by the number of groups. Default: 1</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">filters</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">filters</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.interpolate">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">interpolate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">align_corners</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recompute_scale_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">antialias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/torch/nn/functional.html#interpolate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.interpolate" title="Link to this definition"></a></dt>
<dd><p>Down/up samples the input.</p>
<p>Tensor interpolated to either the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> or the given
<code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code></p>
<p>The algorithm used for interpolation is determined by <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code>.</p>
<p>Currently temporal, spatial and volumetric sampling are supported, i.e.
expected inputs are 3-D, 4-D or 5-D in shape.</p>
<p>The input dimensions are interpreted in the form:
<cite>mini-batch x channels x [optional depth] x [optional height] x width</cite>.</p>
<p>The modes available for resizing are: <cite>nearest</cite>, <cite>linear</cite> (3D-only),
<cite>bilinear</cite>, <cite>bicubic</cite> (4D-only), <cite>trilinear</cite> (5D-only), <cite>area</cite>, <cite>nearest-exact</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a>) – the input tensor</p></li>
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><em>int</em></a><em>]</em>) – output spatial size.</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><em>float</em></a><em>]</em>) – multiplier for spatial size. If <cite>scale_factor</cite> is a tuple,
its length has to match the number of spatial dimensions; <cite>input.dim() - 2</cite>.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><em>str</em></a>) – algorithm used for upsampling:
<code class="docutils literal notranslate"><span class="pre">'nearest'</span></code> | <code class="docutils literal notranslate"><span class="pre">'linear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code> |
<code class="docutils literal notranslate"><span class="pre">'trilinear'</span></code> | <code class="docutils literal notranslate"><span class="pre">'area'</span></code> | <code class="docutils literal notranslate"><span class="pre">'nearest-exact'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code></p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – Geometrically, we consider the pixels of the
input and output as squares rather than points.
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the input and output tensors are aligned by the
center points of their corner pixels, preserving the values at the corner pixels.
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the input and output tensors are aligned by the corner
points of their corner pixels, and the interpolation uses edge value padding
for out-of-boundary values, making this operation <em>independent</em> of input size
when <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code> is kept the same. This only has an effect when <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code>
is <code class="docutils literal notranslate"><span class="pre">'linear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code> or <code class="docutils literal notranslate"><span class="pre">'trilinear'</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>recompute_scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – recompute the scale_factor for use in the
interpolation calculation. If <cite>recompute_scale_factor</cite> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
<cite>scale_factor</cite> must be passed in and <cite>scale_factor</cite> is used to compute the
output <cite>size</cite>. The computed output <cite>size</cite> will be used to infer new scales for
the interpolation. Note that when <cite>scale_factor</cite> is floating-point, it may differ
from the recomputed <cite>scale_factor</cite> due to rounding and precision issues.
If <cite>recompute_scale_factor</cite> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, then <cite>size</cite> or <cite>scale_factor</cite> will
be used directly for interpolation. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>antialias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to apply anti-aliasing. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>. Using anti-alias
option together with <code class="docutils literal notranslate"><span class="pre">align_corners=False</span></code>, interpolation result would match Pillow
result for downsampling operation. Supported modes: <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code>.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With <code class="docutils literal notranslate"><span class="pre">mode='bicubic'</span></code>, it’s possible to cause overshoot. For some dtypes, it can produce
negative values or values greater than 255 for images. Explicitly call <code class="docutils literal notranslate"><span class="pre">result.clamp(min=0,max=255)</span></code>
if you want to reduce the overshoot when displaying the image.
For <code class="docutils literal notranslate"><span class="pre">uint8</span></code> inputs, it already performs saturating cast operation. So, no manual <cite>clamp</cite> operation is needed.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Mode <code class="docutils literal notranslate"><span class="pre">mode='nearest-exact'</span></code> matches Scikit-Image and PIL nearest neighbours interpolation
algorithms and fixes known issues with <code class="docutils literal notranslate"><span class="pre">mode='nearest'</span></code>. This mode is introduced to keep
backward compatibility.
Mode <code class="docutils literal notranslate"><span class="pre">mode='nearest'</span></code> matches buggy OpenCV’s <code class="docutils literal notranslate"><span class="pre">INTER_NEAREST</span></code> interpolation algorithm.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The gradients for the dtype <code class="docutils literal notranslate"><span class="pre">float16</span></code> on CUDA may be inaccurate in the upsample operation
when using modes <code class="docutils literal notranslate"><span class="pre">['linear',</span> <span class="pre">'bilinear',</span> <span class="pre">'bicubic',</span> <span class="pre">'trilinear',</span> <span class="pre">'area']</span></code>.
For more details, please refer to the discussion in
<a class="reference external" href="https://github.com/pytorch/pytorch/issues/104157">issue#104157</a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This operation may produce nondeterministic gradients when given tensors on a CUDA device. See <span class="xref std std-doc">/notes/randomness</span> for more information.</p>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.torch_pad">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">torch_pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.14)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'constant'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.torch_pad" title="Link to this definition"></a></dt>
<dd><p>pad(input, pad, mode=”constant”, value=None) -&gt; Tensor</p>
<p>Pads tensor.</p>
<dl class="simple">
<dt>Padding size:</dt><dd><p>The padding size by which to pad some dimensions of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>
are described starting from the last dimension and moving forward.
<span class="math notranslate nohighlight">\(\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor\)</span> dimensions
of <code class="docutils literal notranslate"><span class="pre">input</span></code> will be padded.
For example, to pad only the last dimension of the input tensor, then
<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.pad" title="foveation.utils.fastaugs.functional_tensor.pad"><code class="xref py py-attr docutils literal notranslate"><span class="pre">pad</span></code></a> has the form
<span class="math notranslate nohighlight">\((\text{padding\_left}, \text{padding\_right})\)</span>;
to pad the last 2 dimensions of the input tensor, then use
<span class="math notranslate nohighlight">\((\text{padding\_left}, \text{padding\_right},\)</span>
<span class="math notranslate nohighlight">\(\text{padding\_top}, \text{padding\_bottom})\)</span>;
to pad the last 3 dimensions, use
<span class="math notranslate nohighlight">\((\text{padding\_left}, \text{padding\_right},\)</span>
<span class="math notranslate nohighlight">\(\text{padding\_top}, \text{padding\_bottom}\)</span>
<span class="math notranslate nohighlight">\(\text{padding\_front}, \text{padding\_back})\)</span>.</p>
</dd>
<dt>Padding mode:</dt><dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CircularPad2d.html#torch.nn.CircularPad2d" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.CircularPad2d</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d.html#torch.nn.ConstantPad2d" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.ConstantPad2d</span></code></a>,
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d.html#torch.nn.ReflectionPad2d" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.ReflectionPad2d</span></code></a>, and <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d.html#torch.nn.ReplicationPad2d" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.ReplicationPad2d</span></code></a>
for concrete examples on how each of the padding modes works. Constant
padding is implemented for arbitrary dimensions. Circular, replicate and
reflection padding are implemented for padding the last 3 dimensions of a
4D or 5D input tensor, the last 2 dimensions of a 3D or 4D input tensor,
or the last dimension of a 2D or 3D input tensor.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using the CUDA backend, this operation may induce nondeterministic
behaviour in its backward pass that is not easily switched off.
Please see the notes on <span class="xref std std-doc">/notes/randomness</span> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="foveation.utils.fastaugs.functional_tensor.Tensor"><em>Tensor</em></a>) – N-dimensional tensor</p></li>
<li><p><strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.14)"><em>tuple</em></a>) – m-elements tuple, where
<span class="math notranslate nohighlight">\(\frac{m}{2} \leq\)</span> input dimensions and <span class="math notranslate nohighlight">\(m\)</span> is even.</p></li>
<li><p><strong>mode</strong> – <code class="docutils literal notranslate"><span class="pre">'constant'</span></code>, <code class="docutils literal notranslate"><span class="pre">'reflect'</span></code>, <code class="docutils literal notranslate"><span class="pre">'replicate'</span></code> or <code class="docutils literal notranslate"><span class="pre">'circular'</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">'constant'</span></code></p></li>
<li><p><strong>value</strong> – fill value for <code class="docutils literal notranslate"><span class="pre">'constant'</span></code> padding. Default: <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t4d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p1d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># pad last dim by 1 on each side</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p1d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># effectively zero padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([3, 3, 4, 4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p2d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># pad last dim by (1, 1) and 2nd to last by (2, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p2d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([3, 3, 8, 4])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t4d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p3d</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># pad by (0, 1), (2, 1), and (3, 3)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">t4d</span><span class="p">,</span> <span class="n">p3d</span><span class="p">,</span> <span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([3, 9, 7, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.get_image_size">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">get_image_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#get_image_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.get_image_size" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.get_image_num_channels">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">get_image_num_channels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#get_image_num_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.get_image_num_channels" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.convert_image_dtype">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">convert_image_dtype</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.8)"><span class="pre">dtype</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">torch.float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#convert_image_dtype"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.convert_image_dtype" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.vflip">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">vflip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#vflip"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.vflip" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.hflip">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">hflip</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#hflip"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.hflip" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.crop">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">crop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">top</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">left</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#crop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.crop" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.rgb_to_grayscale">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">rgb_to_grayscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_output_channels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#rgb_to_grayscale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.rgb_to_grayscale" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_brightness">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_brightness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">brightness_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_brightness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_brightness" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_contrast">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_contrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_contrast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_contrast" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_hue">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_hue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_hue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_hue" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_hue_fast">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_hue_fast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_hue_fast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_hue_fast" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_saturation">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_saturation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_saturation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_saturation" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.mat3">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">mat3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#mat3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.mat3" title="Link to this definition"></a></dt>
<dd><p>Identity matrix with given value</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor._get_sbc_mat">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">_get_sbc_mat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#_get_sbc_mat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor._get_sbc_mat" title="Link to this definition"></a></dt>
<dd><p>adjusting saturation, brightness, and contrast are linear ops, can be combined into one matrix</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.color_jitter">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">color_jitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">brightness_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#color_jitter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.color_jitter" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.random_color_jitter">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">random_color_jitter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hue_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">saturation_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">brightness_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">contrast_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#random_color_jitter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.random_color_jitter" title="Link to this definition"></a></dt>
<dd><p>run color jitter on subset of images specified by idx</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_gamma">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_gamma</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_gamma"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_gamma" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.center_crop">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">center_crop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#center_crop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.center_crop" title="Link to this definition"></a></dt>
<dd><p>DEPRECATED</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.five_crop">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">five_crop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#five_crop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.five_crop" title="Link to this definition"></a></dt>
<dd><p>DEPRECATED</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.ten_crop">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">ten_crop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">vertical_flip</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#ten_crop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.ten_crop" title="Link to this definition"></a></dt>
<dd><p>DEPRECATED</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.pad">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">pad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'constant'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#pad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.pad" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.resize">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">resize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">antialias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#resize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.resize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.affine">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">affine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#affine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.affine" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.rotate">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">rotate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">matrix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'nearest'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.14)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#rotate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.rotate" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.perspective">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">perspective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">perspective_coeffs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.14)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'bilinear'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fill</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.14)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#perspective"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.perspective" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.gaussian_blur">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">gaussian_blur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.List" title="(in Python v3.14)"><span class="pre">List</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#gaussian_blur"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.gaussian_blur" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.invert">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">invert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#invert"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.invert" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.posterize">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">posterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">bits</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.14)"><span class="pre">int</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#posterize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.posterize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.solarize">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">solarize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#solarize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.solarize" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.adjust_sharpness">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">adjust_sharpness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">sharpness_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.14)"><span class="pre">float</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#adjust_sharpness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.adjust_sharpness" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.autocontrast">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">autocontrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#autocontrast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.autocontrast" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="foveation.utils.fastaugs.functional_tensor.equalize">
<span class="sig-prename descclassname"><span class="pre">foveation.utils.fastaugs.functional_tensor.</span></span><span class="sig-name descname"><span class="pre">equalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#foveation.utils.fastaugs.functional_tensor.Tensor" title="torch.Tensor"><span class="pre">Tensor</span></a></span></span><a class="reference internal" href="../_modules/foveation/utils/fastaugs/functional_tensor.html#equalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#foveation.utils.fastaugs.functional_tensor.equalize" title="Link to this definition"></a></dt>
<dd></dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="foveation.utils.fastaugs.functional.html" class="btn btn-neutral float-left" title="foveation.utils.fastaugs.functional" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="foveation.utils.fastaugs.loader.html" class="btn btn-neutral float-right" title="foveation.utils.fastaugs.loader" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>